"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[969],{2648:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>_,frontMatter:()=>r,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"module-4/chapter-5/object-manipulation","title":"Object Manipulation","description":"This chapter covers robotic object manipulation, including grasping, picking, placing, and manipulation planning that enables humanoid robots to interact with objects in their environment.","source":"@site/docs/module-4/chapter-5/object-manipulation.md","sourceDirName":"module-4/chapter-5","slug":"/module-4/chapter-5/object-manipulation","permalink":"/ai-robo-learning/docs/module-4/chapter-5/object-manipulation","draft":false,"unlisted":false,"editUrl":"https://github.com/madnan-github/ai-robo-learning/docs/module-4/chapter-5/object-manipulation.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"title":"Object Manipulation"},"sidebar":"tutorialSidebar","previous":{"title":"Computer Vision for Robotics","permalink":"/ai-robo-learning/docs/module-4/chapter-4/computer-vision-robotics"},"next":{"title":"Capstone Project - Autonomous Humanoid Robot","permalink":"/ai-robo-learning/docs/module-4/chapter-6/capstone-project"}}');var o=t(4848),s=t(8453);const r={sidebar_position:5,title:"Object Manipulation"},i="Object Manipulation",l={},c=[{value:"What You&#39;ll Learn",id:"what-youll-learn",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Robot Kinematics for Manipulation",id:"robot-kinematics-for-manipulation",level:2},{value:"Forward and Inverse Kinematics",id:"forward-and-inverse-kinematics",level:3},{value:"Grasping and Grasp Planning",id:"grasping-and-grasp-planning",level:2},{value:"Grasp Planning Algorithms",id:"grasp-planning-algorithms",level:3},{value:"Manipulation Planning and Execution",id:"manipulation-planning-and-execution",level:2},{value:"Manipulation Planning Node",id:"manipulation-planning-node",level:3},{value:"Force Control and Tactile Feedback",id:"force-control-and-tactile-feedback",level:2},{value:"Force-Controlled Manipulation",id:"force-controlled-manipulation",level:3},{value:"Multi-Fingered Hand Control",id:"multi-fingered-hand-control",level:2},{value:"Multi-Fingered Grasp Control",id:"multi-fingered-grasp-control",level:3},{value:"Hands-on Lab: Complete Manipulation System",id:"hands-on-lab-complete-manipulation-system",level:2},{value:"Step 1: Create the Manipulation System Launch File",id:"step-1-create-the-manipulation-system-launch-file",level:3},{value:"Step 2: Create the Complete Manipulation Node",id:"step-2-create-the-complete-manipulation-node",level:3},{value:"Step 3: Test the Manipulation System",id:"step-3-test-the-manipulation-system",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"Next Steps",id:"next-steps",level:2}];function p(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"object-manipulation",children:"Object Manipulation"})}),"\n",(0,o.jsx)(n.p,{children:"This chapter covers robotic object manipulation, including grasping, picking, placing, and manipulation planning that enables humanoid robots to interact with objects in their environment."}),"\n",(0,o.jsx)(n.h2,{id:"what-youll-learn",children:"What You'll Learn"}),"\n",(0,o.jsx)(n.p,{children:"In this chapter, you'll explore:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Robot kinematics and inverse kinematics for manipulation"}),"\n",(0,o.jsx)(n.li,{children:"Grasping and grasp planning algorithms"}),"\n",(0,o.jsx)(n.li,{children:"Manipulation planning and execution"}),"\n",(0,o.jsx)(n.li,{children:"Force control and tactile feedback"}),"\n",(0,o.jsx)(n.li,{children:"Object recognition for manipulation"}),"\n",(0,o.jsx)(n.li,{children:"Multi-fingered hand control"}),"\n",(0,o.jsx)(n.li,{children:"Manipulation safety and validation"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Completion of Module 1-4, Chapters 1-4"}),"\n",(0,o.jsx)(n.li,{children:"Understanding of ROS 2 messaging and action servers"}),"\n",(0,o.jsx)(n.li,{children:"Knowledge of robot kinematics"}),"\n",(0,o.jsx)(n.li,{children:"Experience with Python and robotics libraries"}),"\n",(0,o.jsx)(n.li,{children:"Understanding of coordinate systems and transformations"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"robot-kinematics-for-manipulation",children:"Robot Kinematics for Manipulation"}),"\n",(0,o.jsx)(n.h3,{id:"forward-and-inverse-kinematics",children:"Forward and Inverse Kinematics"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import Float32MultiArray\nfrom geometry_msgs.msg import Pose, Point\nfrom sensor_msgs.msg import JointState\nimport numpy as np\nimport math\nfrom scipy.spatial.transform import Rotation as R\n\nclass ManipulationKinematics(Node):\n    def __init__(self):\n        super().__init__(\'manipulation_kinematics\')\n\n        # Subscribe to joint states\n        self.joint_sub = self.create_subscription(\n            JointState,\n            \'/joint_states\',\n            self.joint_state_callback,\n            10\n        )\n\n        # Publishers\n        self.end_effector_pub = self.create_publisher(Pose, \'/end_effector_pose\', 10)\n        self.ik_solution_pub = self.create_publisher(Float32MultiArray, \'/ik_solution\', 10)\n\n        # Robot parameters (example for 6-DOF manipulator)\n        self.dh_parameters = [\n            # [a, alpha, d, theta_offset]\n            [0.0, math.pi/2, 0.1, 0.0],    # Joint 1\n            [0.4, 0.0, 0.0, 0.0],          # Joint 2\n            [0.0, math.pi/2, 0.0, 0.0],    # Joint 3\n            [0.0, -math.pi/2, 0.4, 0.0],   # Joint 4\n            [0.0, math.pi/2, 0.0, 0.0],    # Joint 5\n            [0.0, 0.0, 0.1, 0.0]           # Joint 6\n        ]\n\n        # Current joint angles\n        self.current_joints = np.zeros(6)\n\n        # Kinematics cache\n        self.fk_cache = None\n\n        self.get_logger().info(\'Manipulation Kinematics initialized\')\n\n    def joint_state_callback(self, msg):\n        """Update joint states"""\n        if len(msg.position) >= 6:\n            self.current_joints = np.array(msg.position[:6])\n            # Calculate forward kinematics\n            ee_pose = self.forward_kinematics(self.current_joints)\n            if ee_pose is not None:\n                self.end_effector_pub.publish(ee_pose)\n\n    def dh_transform(self, a, alpha, d, theta):\n        """Calculate Denavit-Hartenberg transformation matrix"""\n        sa = math.sin(alpha)\n        ca = math.cos(alpha)\n        st = math.sin(theta)\n        ct = math.cos(theta)\n\n        transform = np.array([\n            [ct, -st * ca, st * sa, a * ct],\n            [st, ct * ca, -ct * sa, a * st],\n            [0, sa, ca, d],\n            [0, 0, 0, 1]\n        ])\n        return transform\n\n    def forward_kinematics(self, joint_angles):\n        """Calculate forward kinematics"""\n        try:\n            # Calculate transformation matrices for each joint\n            T = np.eye(4)  # Identity matrix\n\n            for i in range(len(self.dh_parameters)):\n                a, alpha, d, theta_offset = self.dh_parameters[i]\n                theta = joint_angles[i] + theta_offset\n                Ti = self.dh_transform(a, alpha, d, theta)\n                T = T @ Ti\n\n            # Extract position and orientation\n            position = T[:3, 3]\n            rotation_matrix = T[:3, :3]\n\n            # Convert rotation matrix to quaternion\n            quat = self.rotation_matrix_to_quaternion(rotation_matrix)\n\n            # Create Pose message\n            pose = Pose()\n            pose.position.x = float(position[0])\n            pose.position.y = float(position[1])\n            pose.position.z = float(position[2])\n            pose.orientation.x = float(quat[0])\n            pose.orientation.y = float(quat[1])\n            pose.orientation.z = float(quat[2])\n            pose.orientation.w = float(quat[3])\n\n            return pose\n\n        except Exception as e:\n            self.get_logger().error(f\'Forward kinematics error: {str(e)}\')\n            return None\n\n    def inverse_kinematics(self, target_pose):\n        """Calculate inverse kinematics (simplified analytical solution)"""\n        try:\n            # Extract target position\n            target_pos = np.array([\n                target_pose.position.x,\n                target_pose.position.y,\n                target_pose.position.z\n            ])\n\n            # Simplified analytical IK for 6-DOF manipulator\n            # This is a highly simplified version - real IK would be more complex\n            x, y, z = target_pos\n\n            # Calculate joint angles (simplified example)\n            theta1 = math.atan2(y, x)\n\n            # Calculate distance to target in XY plane\n            r = math.sqrt(x**2 + y**2)\n\n            # Calculate Z distance\n            z_eff = z - self.dh_parameters[0][2]  # Subtract base height\n\n            # Calculate remaining joint angles based on arm geometry\n            # This is a simplified calculation\n            l2 = self.dh_parameters[1][0]  # Upper arm length\n            l3 = self.dh_parameters[3][2]  # Forearm length\n\n            # Distance from shoulder to target\n            d = math.sqrt(r**2 + z_eff**2)\n\n            # Shoulder angle\n            cos_theta2 = (l2**2 + d**2 - l3**2) / (2 * l2 * d)\n            cos_theta2 = max(-1, min(1, cos_theta2))  # Clamp to [-1, 1]\n            theta2 = math.acos(cos_theta2) - math.atan2(z_eff, r)\n\n            # Elbow angle\n            cos_theta3 = (l2**2 + l3**2 - d**2) / (2 * l2 * l3)\n            cos_theta3 = max(-1, min(1, cos_theta3))  # Clamp to [-1, 1]\n            theta3 = math.pi - math.acos(cos_theta3)\n\n            # Remaining joints (simplified)\n            theta4 = 0.0\n            theta5 = 0.0\n            theta6 = 0.0\n\n            # Create solution\n            solution = np.array([theta1, theta2, theta3, theta4, theta5, theta6])\n\n            return solution\n\n        except Exception as e:\n            self.get_logger().error(f\'Inverse kinematics error: {str(e)}\')\n            return None\n\n    def rotation_matrix_to_quaternion(self, R):\n        """Convert rotation matrix to quaternion"""\n        trace = np.trace(R)\n        if trace > 0:\n            s = np.sqrt(trace + 1.0) * 2\n            qw = 0.25 * s\n            qx = (R[2, 1] - R[1, 2]) / s\n            qy = (R[0, 2] - R[2, 0]) / s\n            qz = (R[1, 0] - R[0, 1]) / s\n        else:\n            if R[0, 0] > R[1, 1] and R[0, 0] > R[2, 2]:\n                s = np.sqrt(1.0 + R[0, 0] - R[1, 1] - R[2, 2]) * 2\n                qw = (R[2, 1] - R[1, 2]) / s\n                qx = 0.25 * s\n                qy = (R[0, 1] + R[1, 0]) / s\n                qz = (R[0, 2] + R[2, 0]) / s\n            elif R[1, 1] > R[2, 2]:\n                s = np.sqrt(1.0 + R[1, 1] - R[0, 0] - R[2, 2]) * 2\n                qw = (R[0, 2] - R[2, 0]) / s\n                qx = (R[0, 1] + R[1, 0]) / s\n                qy = 0.25 * s\n                qz = (R[1, 2] + R[2, 1]) / s\n            else:\n                s = np.sqrt(1.0 + R[2, 2] - R[0, 0] - R[1, 1]) * 2\n                qw = (R[1, 0] - R[0, 1]) / s\n                qx = (R[0, 2] + R[2, 0]) / s\n                qy = (R[1, 2] + R[2, 1]) / s\n                qz = 0.25 * s\n\n        return [qx, qy, qz, qw]\n\n    def solve_ik_for_pose(self, target_pose):\n        """Solve inverse kinematics and publish solution"""\n        ik_solution = self.inverse_kinematics(target_pose)\n\n        if ik_solution is not None:\n            # Publish solution\n            solution_msg = Float32MultiArray()\n            solution_msg.data = ik_solution.tolist()\n            self.ik_solution_pub.publish(solution_msg)\n\n            return ik_solution\n        else:\n            return None\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = ManipulationKinematics()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        print("Shutting down manipulation kinematics...")\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,o.jsx)(n.h2,{id:"grasping-and-grasp-planning",children:"Grasping and Grasp Planning"}),"\n",(0,o.jsx)(n.h3,{id:"grasp-planning-algorithms",children:"Grasp Planning Algorithms"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Pose, Point\nfrom std_msgs.msg import String\nfrom sensor_msgs.msg import PointCloud2\nfrom visualization_msgs.msg import Marker, MarkerArray\nfrom cv_bridge import CvBridge\nimport numpy as np\nimport math\nimport threading\nfrom scipy.spatial import KDTree\n\nclass GraspPlanner(Node):\n    def __init__(self):\n        super().__init__(\'grasp_planner\')\n\n        # Subscribe to object information\n        self.object_sub = self.create_subscription(\n            String,\n            \'/detected_object\',\n            self.object_callback,\n            10\n        )\n\n        self.pointcloud_sub = self.create_subscription(\n            PointCloud2,\n            \'/object_pointcloud\',\n            self.pointcloud_callback,\n            10\n        )\n\n        # Publishers\n        self.grasp_poses_pub = self.create_publisher(Pose, \'/grasp_pose\', 10)\n        self.grasp_candidates_pub = self.create_publisher(MarkerArray, \'/grasp_candidates\', 10)\n\n        # CV Bridge\n        self.bridge = CvBridge()\n\n        # Grasp planning parameters\n        self.grasp_approach_distance = 0.1  # meters\n        self.grasp_depth = 0.05  # meters\n        self.grasp_width = 0.1  # meters\n        self.min_grasp_quality = 0.7\n\n        # Object information\n        self.object_info = None\n        self.object_points = None\n\n        # Threading\n        self.grasp_lock = threading.Lock()\n\n        self.get_logger().info(\'Grasp Planner initialized\')\n\n    def object_callback(self, msg):\n        """Process detected object information"""\n        try:\n            # Parse object information from message\n            object_data = eval(msg.data)  # In practice, use proper serialization\n            self.object_info = object_data\n\n            # Plan grasps for the object\n            self.plan_grasps()\n\n        except Exception as e:\n            self.get_logger().error(f\'Object callback error: {str(e)}\')\n\n    def pointcloud_callback(self, msg):\n        """Process object point cloud"""\n        try:\n            # Convert PointCloud2 to numpy array (simplified)\n            # In practice, use sensor_msgs_py.point_cloud2.read_points\n            self.object_points = self.pointcloud_to_array(msg)\n            self.get_logger().info(f\'Received object point cloud with {len(self.object_points) if self.object_points is not None else 0} points\')\n\n        except Exception as e:\n            self.get_logger().error(f\'Point cloud callback error: {str(e)}\')\n\n    def pointcloud_to_array(self, pointcloud_msg):\n        """Convert PointCloud2 message to numpy array"""\n        # This is a simplified version\n        # In practice, use sensor_msgs_py.point_cloud2.read_points\n        try:\n            # For simulation, return random points\n            # In real implementation, extract x, y, z coordinates\n            return np.random.rand(100, 3) * 0.5  # Random points for simulation\n        except:\n            return None\n\n    def plan_grasps(self):\n        """Plan possible grasp poses for the object"""\n        if self.object_info is None:\n            return\n\n        with self.grasp_lock:\n            object_center = self.calculate_object_center()\n            object_dimensions = self.calculate_object_dimensions()\n\n            if object_center is not None and object_dimensions is not None:\n                # Generate grasp candidates\n                grasp_candidates = self.generate_grasp_candidates(object_center, object_dimensions)\n\n                # Evaluate grasp quality\n                high_quality_grasps = self.evaluate_grasps(grasp_candidates)\n\n                if high_quality_grasps:\n                    # Select the best grasp\n                    best_grasp = self.select_best_grasp(high_quality_grasps)\n\n                    # Publish the best grasp\n                    self.grasp_poses_pub.publish(best_grasp)\n\n                    # Publish visualization markers\n                    self.publish_grasp_candidates(high_quality_grasps)\n\n                    self.get_logger().info(f\'Published best grasp for {self.object_info.get("label", "unknown")}\')\n\n    def calculate_object_center(self):\n        """Calculate object center from point cloud"""\n        if self.object_points is not None and len(self.object_points) > 0:\n            center = np.mean(self.object_points, axis=0)\n            return center\n        elif self.object_info:\n            # If point cloud not available, use bounding box center\n            bbox = self.object_info.get(\'bbox\', [0, 0, 0, 0])\n            center_x = (bbox[0] + bbox[2]) / 2.0\n            center_y = (bbox[1] + bbox[3]) / 2.0\n            # Depth would come from other sensors\n            return np.array([center_x, center_y, 0.5])\n\n        return None\n\n    def calculate_object_dimensions(self):\n        """Calculate object dimensions from point cloud"""\n        if self.object_points is not None and len(self.object_points) > 0:\n            min_vals = np.min(self.object_points, axis=0)\n            max_vals = np.max(self.object_points, axis=0)\n            dimensions = max_vals - min_vals\n            return dimensions\n        elif self.object_info:\n            # If point cloud not available, use bounding box dimensions\n            bbox = self.object_info.get(\'bbox\', [0, 0, 1, 1])\n            width = bbox[2] - bbox[0]\n            height = bbox[3] - bbox[1]\n            depth = 0.1  # Default depth if not known\n            return np.array([width, height, depth])\n\n        return None\n\n    def generate_grasp_candidates(self, object_center, object_dimensions):\n        """Generate potential grasp poses around the object"""\n        candidates = []\n\n        # Generate grasps from different directions\n        directions = [\n            [1, 0, 0],   # Right\n            [-1, 0, 0],  # Left\n            [0, 1, 0],   # Front\n            [0, -1, 0],  # Back\n            [0, 0, 1],   # Top\n            [0, 0, -1]   # Bottom\n        ]\n\n        for direction in directions:\n            # Calculate grasp position\n            grasp_pos = object_center + np.array(direction) * self.grasp_approach_distance\n\n            # Calculate grasp orientation based on approach direction\n            grasp_orientation = self.calculate_grasp_orientation(direction)\n\n            # Create grasp pose\n            grasp_pose = Pose()\n            grasp_pose.position.x = float(grasp_pos[0])\n            grasp_pose.position.y = float(grasp_pos[1])\n            grasp_pose.position.z = float(grasp_pos[2])\n            grasp_pose.orientation.x = float(grasp_orientation[0])\n            grasp_pose.orientation.y = float(grasp_orientation[1])\n            grasp_pose.orientation.z = float(grasp_orientation[2])\n            grasp_pose.orientation.w = float(grasp_orientation[3])\n\n            candidates.append(grasp_pose)\n\n        return candidates\n\n    def calculate_grasp_orientation(self, approach_direction):\n        """Calculate grasp orientation based on approach direction"""\n        # Normalize approach direction\n        approach = np.array(approach_direction)\n        approach = approach / np.linalg.norm(approach)\n\n        # Calculate orientation that aligns gripper with approach direction\n        # This is a simplified calculation\n        if np.allclose(approach, [0, 0, 1]):  # Top-down grasp\n            # Grasp from above, gripper aligned with Z-axis\n            rotation = R.from_rotvec([0, 0, 0])\n        elif np.allclose(approach, [1, 0, 0]):  # Side grasp along X\n            rotation = R.from_rotvec([0, math.pi/2, 0])\n        elif np.allclose(approach, [0, 1, 0]):  # Side grasp along Y\n            rotation = R.from_rotvec([0, 0, -math.pi/2])\n        else:\n            # General case - align Z-axis of gripper with approach direction\n            z_axis = np.array([0, 0, 1])\n            if not np.allclose(approach, z_axis) and not np.allclose(approach, -z_axis):\n                # Calculate rotation to align Z with approach\n                rotation_axis = np.cross(z_axis, approach)\n                rotation_axis = rotation_axis / np.linalg.norm(rotation_axis)\n                angle = math.acos(np.dot(z_axis, approach))\n                rotation = R.from_rotvec(rotation_axis * angle)\n            else:\n                rotation = R.from_rotvec([0, 0, 0])\n\n        return rotation.as_quat()\n\n    def evaluate_grasps(self, grasp_candidates):\n        """Evaluate grasp quality for each candidate"""\n        evaluated_grasps = []\n\n        for grasp_pose in grasp_candidates:\n            quality = self.evaluate_grasp_quality(grasp_pose)\n            if quality >= self.min_grasp_quality:\n                evaluated_grasps.append((grasp_pose, quality))\n\n        # Sort by quality\n        evaluated_grasps.sort(key=lambda x: x[1], reverse=True)\n\n        return evaluated_grasps\n\n    def evaluate_grasp_quality(self, grasp_pose):\n        """Evaluate the quality of a grasp pose"""\n        # In a real system, this would use more sophisticated metrics\n        # For simulation, use simple heuristics\n\n        # Check if grasp is in reach\n        distance_from_base = math.sqrt(\n            grasp_pose.position.x**2 +\n            grasp_pose.position.y**2 +\n            grasp_pose.position.z**2\n        )\n\n        if distance_from_base > 1.0:  # Beyond typical reach\n            return 0.0\n\n        # Check if grasp is stable (simplified)\n        # For a top-down grasp, check if object is stable\n        approach_direction = np.array([\n            grasp_pose.position.x,\n            grasp_pose.position.y,\n            grasp_pose.position.z\n        ])\n        approach_direction = approach_direction / np.linalg.norm(approach_direction)\n\n        # Stability based on approach direction\n        stability = abs(approach_direction[2])  # Z component for top-down stability\n\n        # Size consideration - larger objects might be harder to grasp\n        if self.object_info:\n            size_factor = min(1.0, 0.2 / self.object_info.get(\'size\', 0.1))\n        else:\n            size_factor = 1.0\n\n        quality = stability * size_factor\n\n        return min(1.0, max(0.0, quality))\n\n    def select_best_grasp(self, evaluated_grasps):\n        """Select the best grasp from evaluated candidates"""\n        if evaluated_grasps:\n            return evaluated_grasps[0][0]  # Return the pose with highest quality\n        else:\n            return None\n\n    def publish_grasp_candidates(self, evaluated_grasps):\n        """Publish visualization markers for grasp candidates"""\n        marker_array = MarkerArray()\n\n        for i, (grasp_pose, quality) in enumerate(evaluated_grasps):\n            # Create marker for grasp pose\n            marker = Marker()\n            marker.header.frame_id = "base_link"\n            marker.header.stamp = self.get_clock().now().to_msg()\n            marker.ns = "grasp_candidates"\n            marker.id = i\n            marker.type = Marker.ARROW\n            marker.action = Marker.ADD\n\n            # Set position and orientation\n            marker.pose = grasp_pose\n\n            # Set scale (length and width of arrow)\n            marker.scale.x = 0.1  # Arrow shaft length\n            marker.scale.y = 0.01  # Arrow shaft diameter\n            marker.scale.z = 0.02  # Arrow head diameter\n\n            # Set color based on quality\n            marker.color.r = 1.0 - quality  # Red decreases with quality\n            marker.color.g = quality      # Green increases with quality\n            marker.color.b = 0.0\n            marker.color.a = 1.0\n\n            marker_array.markers.append(marker)\n\n        self.grasp_candidates_pub.publish(marker_array)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = GraspPlanner()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        print("Shutting down grasp planner...")\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,o.jsx)(n.h2,{id:"manipulation-planning-and-execution",children:"Manipulation Planning and Execution"}),"\n",(0,o.jsx)(n.h3,{id:"manipulation-planning-node",children:"Manipulation Planning Node"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nfrom geometry_msgs.msg import Pose, Point\nfrom sensor_msgs.msg import JointState\nfrom action_msgs.msg import GoalStatus\nfrom rclpy.action import ActionServer, GoalResponse, CancelResponse\nfrom rclpy.executors import MultiThreadedExecutor\nimport numpy as np\nimport math\nimport threading\nimport time\n\nclass ManipulationPlanner(Node):\n    def __init__(self):\n        super().__init__(\'manipulation_planner\')\n\n        # Subscribe to object and grasp information\n        self.object_sub = self.create_subscription(\n            String,\n            \'/object_to_manipulate\',\n            self.object_callback,\n            10\n        )\n\n        self.grasp_sub = self.create_subscription(\n            Pose,\n            \'/selected_grasp\',\n            self.grasp_callback,\n            10\n        )\n\n        # Publishers\n        self.joint_cmd_pub = self.create_publisher(JointState, \'/joint_commands\', 10)\n        self.manipulation_status_pub = self.create_publisher(String, \'/manipulation_status\', 10)\n\n        # Action server for manipulation tasks\n        self._action_server = ActionServer(\n            self,\n            ManipulationAction,\n            \'manipulate_object\',\n            self.execute_manipulation_callback,\n            goal_callback=self.goal_callback,\n            cancel_callback=self.cancel_callback\n        )\n\n        # Manipulation state\n        self.current_object = None\n        self.selected_grasp = None\n        self.robot_joints = np.zeros(6)\n        self.manipulation_active = False\n\n        # Manipulation parameters\n        self.approach_distance = 0.1\n        self.lift_height = 0.2\n        self.place_height = 0.1\n\n        # Threading\n        self.manipulation_lock = threading.Lock()\n\n        self.get_logger().info(\'Manipulation Planner initialized\')\n\n    def object_callback(self, msg):\n        """Process object to manipulate"""\n        try:\n            self.current_object = eval(msg.data)  # In practice, use proper deserialization\n            self.get_logger().info(f\'New object to manipulate: {self.current_object.get("label", "unknown")}\')\n        except Exception as e:\n            self.get_logger().error(f\'Object callback error: {str(e)}\')\n\n    def grasp_callback(self, msg):\n        """Process selected grasp pose"""\n        self.selected_grasp = msg\n        self.get_logger().info(\'Received selected grasp pose\')\n\n    def goal_callback(self, goal_request):\n        """Handle manipulation goal request"""\n        self.get_logger().info(f\'Received manipulation goal: {goal_request.action}\')\n        return GoalResponse.ACCEPT\n\n    def cancel_callback(self, goal_handle):\n        """Handle manipulation goal cancellation"""\n        self.get_logger().info(\'Received manipulation goal cancellation\')\n        return CancelResponse.ACCEPT\n\n    async def execute_manipulation_callback(self, goal_handle):\n        """Execute manipulation task"""\n        self.get_logger().info(\'Executing manipulation task\')\n\n        feedback_msg = ManipulationAction.Feedback()\n        result = ManipulationAction.Result()\n\n        with self.manipulation_lock:\n            try:\n                action = goal_handle.request.action\n                target_pose = goal_handle.request.target_pose\n\n                if action == "pick":\n                    success = await self.execute_pick_task(target_pose, feedback_msg)\n                elif action == "place":\n                    success = await self.execute_place_task(target_pose, feedback_msg)\n                elif action == "move":\n                    success = await self.execute_move_task(target_pose, feedback_msg)\n                else:\n                    self.get_logger().error(f\'Unknown manipulation action: {action}\')\n                    success = False\n\n                if success:\n                    goal_handle.succeed()\n                    result.success = True\n                    result.message = f\'Successfully completed {action} action\'\n                else:\n                    goal_handle.abort()\n                    result.success = False\n                    result.message = f\'Failed to complete {action} action\'\n\n            except Exception as e:\n                self.get_logger().error(f\'Manipulation execution error: {str(e)}\')\n                goal_handle.abort()\n                result.success = False\n                result.message = f\'Execution error: {str(e)}\'\n\n        return result\n\n    async def execute_pick_task(self, target_pose, feedback_msg):\n        """Execute pick task"""\n        self.get_logger().info(\'Executing pick task\')\n\n        # Step 1: Approach the object\n        approach_pose = self.calculate_approach_pose(target_pose)\n        if not await self.move_to_pose(approach_pose, feedback_msg, "approaching_object"):\n            return False\n\n        # Step 2: Move to grasp position\n        if not await self.move_to_pose(target_pose, feedback_msg, "moving_to_grasp"):\n            return False\n\n        # Step 3: Close gripper\n        if not await self.close_gripper(feedback_msg):\n            return False\n\n        # Step 4: Lift object\n        lift_pose = self.calculate_lift_pose(target_pose)\n        if not await self.move_to_pose(lift_pose, feedback_msg, "lifting_object"):\n            return False\n\n        self.get_logger().info(\'Pick task completed successfully\')\n        return True\n\n    async def execute_place_task(self, target_pose, feedback_msg):\n        """Execute place task"""\n        self.get_logger().info(\'Executing place task\')\n\n        # Step 1: Approach placement location\n        approach_pose = self.calculate_approach_pose(target_pose)\n        if not await self.move_to_pose(approach_pose, feedback_msg, "approaching_placement"):\n            return False\n\n        # Step 2: Move to placement position\n        if not await self.move_to_pose(target_pose, feedback_msg, "moving_to_placement"):\n            return False\n\n        # Step 3: Open gripper\n        if not await self.open_gripper(feedback_msg):\n            return False\n\n        # Step 4: Retreat\n        retreat_pose = self.calculate_retreat_pose(target_pose)\n        if not await self.move_to_pose(retreat_pose, feedback_msg, "retreating"):\n            return False\n\n        self.get_logger().info(\'Place task completed successfully\')\n        return True\n\n    async def execute_move_task(self, target_pose, feedback_msg):\n        """Execute move task"""\n        self.get_logger().info(\'Executing move task\')\n\n        # Simply move to the target pose\n        if not await self.move_to_pose(target_pose, feedback_msg, "moving_to_target"):\n            return False\n\n        self.get_logger().info(\'Move task completed successfully\')\n        return True\n\n    def calculate_approach_pose(self, target_pose):\n        """Calculate approach pose before grasping"""\n        approach_pose = Pose()\n        approach_pose.position = target_pose.position\n        approach_pose.orientation = target_pose.orientation\n\n        # Move back slightly along approach direction\n        approach_direction = self.calculate_approach_vector(target_pose)\n        approach_pose.position.x -= approach_direction[0] * self.approach_distance\n        approach_pose.position.y -= approach_direction[1] * self.approach_distance\n        approach_pose.position.z -= approach_direction[2] * self.approach_distance\n\n        return approach_pose\n\n    def calculate_lift_pose(self, grasp_pose):\n        """Calculate lift pose after grasping"""\n        lift_pose = Pose()\n        lift_pose.position = grasp_pose.position\n        lift_pose.orientation = grasp_pose.orientation\n\n        # Move up\n        lift_pose.position.z += self.lift_height\n\n        return lift_pose\n\n    def calculate_retreat_pose(self, place_pose):\n        """Calculate retreat pose after placing"""\n        retreat_pose = Pose()\n        retreat_pose.position = place_pose.position\n        retreat_pose.orientation = place_pose.orientation\n\n        # Move back slightly\n        retreat_pose.position.z += self.approach_distance\n\n        return retreat_pose\n\n    def calculate_approach_vector(self, target_pose):\n        """Calculate approach vector from orientation"""\n        # Extract approach direction from orientation quaternion\n        # This is simplified - in practice, use the orientation to determine approach direction\n        return [0, 0, -1]  # Default: approach from above\n\n    async def move_to_pose(self, target_pose, feedback_msg, stage):\n        """Move end effector to target pose"""\n        try:\n            # In a real system, this would solve IK and send joint commands\n            # For simulation, we\'ll just publish a status update\n\n            # Publish feedback\n            feedback_msg.current_stage = stage\n            feedback_msg.progress = 0.0\n\n            # Simulate movement (in real system, this would be actual movement)\n            for i in range(10):  # Simulate 10 steps\n                feedback_msg.progress = (i + 1) / 10.0\n                goal_handle.publish_feedback(feedback_msg)\n                await rclpy.sleep(0.1)  # Simulate movement time\n\n            self.get_logger().info(f\'Moved to pose for {stage}\')\n            return True\n\n        except Exception as e:\n            self.get_logger().error(f\'Move to pose error: {str(e)}\')\n            return False\n\n    async def close_gripper(self, feedback_msg):\n        """Close gripper to grasp object"""\n        try:\n            # Simulate gripper closing\n            self.get_logger().info(\'Closing gripper\')\n\n            # Publish gripper command (in real system)\n            # gripper_cmd_msg = Float64()\n            # gripper_cmd_msg.data = 0.0  # Closed position\n            # self.gripper_pub.publish(gripper_cmd_msg)\n\n            # Simulate gripper closing time\n            await rclpy.sleep(0.5)\n\n            return True\n\n        except Exception as e:\n            self.get_logger().error(f\'Close gripper error: {str(e)}\')\n            return False\n\n    async def open_gripper(self, feedback_msg):\n        """Open gripper to release object"""\n        try:\n            # Simulate gripper opening\n            self.get_logger().info(\'Opening gripper\')\n\n            # Publish gripper command (in real system)\n            # gripper_cmd_msg = Float64()\n            # gripper_cmd_msg.data = 1.0  # Open position\n            # self.gripper_pub.publish(gripper_cmd_msg)\n\n            # Simulate gripper opening time\n            await rclpy.sleep(0.5)\n\n            return True\n\n        except Exception as e:\n            self.get_logger().error(f\'Open gripper error: {str(e)}\')\n            return False\n\n    def publish_manipulation_status(self, status):\n        """Publish manipulation status"""\n        status_msg = String()\n        status_msg.data = status\n        self.manipulation_status_pub.publish(status_msg)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = ManipulationPlanner()\n\n    try:\n        executor = MultiThreadedExecutor()\n        rclpy.spin(node, executor=executor)\n    except KeyboardInterrupt:\n        print("Shutting down manipulation planner...")\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,o.jsx)(n.h2,{id:"force-control-and-tactile-feedback",children:"Force Control and Tactile Feedback"}),"\n",(0,o.jsx)(n.h3,{id:"force-controlled-manipulation",children:"Force-Controlled Manipulation"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Wrench, WrenchStamped\nfrom sensor_msgs.msg import JointState\nfrom std_msgs.msg import Float32\nimport numpy as np\nimport math\nimport threading\n\nclass ForceControlledManipulator(Node):\n    def __init__(self):\n        super().__init__(\'force_controlled_manipulator\')\n\n        # Subscribe to force/torque sensor\n        self.force_sub = self.create_subscription(\n            WrenchStamped,\n            \'/wrench\',\n            self.force_callback,\n            10\n        )\n\n        # Subscribe to joint states\n        self.joint_sub = self.create_subscription(\n            JointState,\n            \'/joint_states\',\n            self.joint_state_callback,\n            10\n        )\n\n        # Publishers\n        self.force_cmd_pub = self.create_publisher(Wrench, \'/force_command\', 10)\n        self.joint_cmd_pub = self.create_publisher(JointState, \'/joint_commands\', 10)\n        self.contact_status_pub = self.create_publisher(Float32, \'/contact_force\', 10)\n\n        # Force control parameters\n        self.desired_force = np.array([0.0, 0.0, 5.0])  # 5N downward force\n        self.force_tolerance = 0.5  # 0.5N tolerance\n        self.stiffness = 100.0  # N/m stiffness\n        self.damping = 10.0     # N*s/m damping\n\n        # Current state\n        self.current_force = np.array([0.0, 0.0, 0.0])\n        self.current_joints = np.zeros(6)\n        self.contact_threshold = 2.0  # N\n\n        # Force control state\n        self.force_control_active = False\n        self.impedance_control_active = False\n\n        # Threading\n        self.force_control_lock = threading.Lock()\n\n        self.get_logger().info(\'Force-Controlled Manipulator initialized\')\n\n    def force_callback(self, msg):\n        """Process force/torque sensor data"""\n        with self.force_control_lock:\n            self.current_force = np.array([\n                msg.wrench.force.x,\n                msg.wrench.force.y,\n                msg.wrench.force.z\n            ])\n\n            # Publish contact status\n            contact_force = math.sqrt(sum(f**2 for f in self.current_force))\n            contact_msg = Float32()\n            contact_msg.data = contact_force\n            self.contact_status_pub.publish(contact_msg)\n\n            # Check if contact is detected\n            if contact_force > self.contact_threshold:\n                self.get_logger().info(f\'Contact detected: {contact_force:.2f}N\')\n\n            # Execute force control if active\n            if self.force_control_active:\n                self.execute_force_control()\n\n    def joint_state_callback(self, msg):\n        """Update joint states"""\n        if len(msg.position) >= 6:\n            self.current_joints = np.array(msg.position[:6])\n\n    def execute_force_control(self):\n        """Execute force control algorithm"""\n        if not self.force_control_active:\n            return\n\n        # Calculate force error\n        force_error = self.desired_force - self.current_force\n\n        # Simple PID-based force control\n        force_command = self.calculate_force_command(force_error)\n\n        # Publish force command\n        wrench_msg = Wrench()\n        wrench_msg.force.x = float(force_command[0])\n        wrench_msg.force.y = float(force_command[1])\n        wrench_msg.force.z = float(force_command[2])\n        # Torque commands would go here if needed\n        self.force_cmd_pub.publish(wrench_msg)\n\n        # Log force control status\n        self.get_logger().info(f\'Force control - Desired: {self.desired_force}, Actual: {self.current_force}, Error: {force_error}\')\n\n    def calculate_force_command(self, force_error):\n        """Calculate force command based on error"""\n        # Simple proportional control\n        kp = 1.0  # Proportional gain\n        force_command = kp * force_error\n\n        # Limit command magnitude\n        max_force = 10.0  # N\n        force_magnitude = np.linalg.norm(force_command)\n        if force_magnitude > max_force:\n            force_command = (force_command / force_magnitude) * max_force\n\n        return force_command\n\n    def execute_impedance_control(self, desired_position, desired_stiffness=None, desired_damping=None):\n        """Execute impedance control"""\n        if not self.impedance_control_active:\n            return\n\n        # Calculate position error\n        current_position = self.get_end_effector_position()\n        position_error = desired_position - current_position\n\n        # Calculate desired force based on impedance model\n        if desired_stiffness is not None:\n            stiffness = desired_stiffness\n        else:\n            stiffness = self.stiffness\n\n        if desired_damping is not None:\n            damping = desired_damping\n        else:\n            damping = self.damping\n\n        # Impedance model: F = K(x_d - x) + D(v_d - v)\n        # For position control: F = K(x_d - x)\n        desired_force = stiffness * position_error\n\n        # Apply force command\n        wrench_msg = Wrench()\n        wrench_msg.force.x = float(desired_force[0])\n        wrench_msg.force.y = float(desired_force[1])\n        wrench_msg.force.z = float(desired_force[2])\n        self.force_cmd_pub.publish(wrench_msg)\n\n    def get_end_effector_position(self):\n        """Get end effector position (simplified)"""\n        # In a real system, this would use forward kinematics\n        # For simulation, return current joint-based position\n        # This is a simplified approximation\n        return np.array([self.current_joints[0], self.current_joints[1], self.current_joints[2]])\n\n    def start_force_control(self, desired_force):\n        """Start force control with desired force"""\n        with self.force_control_lock:\n            self.desired_force = np.array(desired_force)\n            self.force_control_active = True\n            self.get_logger().info(f\'Started force control with desired force: {self.desired_force}\')\n\n    def stop_force_control(self):\n        """Stop force control"""\n        with self.force_control_lock:\n            self.force_control_active = False\n            self.get_logger().info(\'Stopped force control\')\n\n    def start_impedance_control(self):\n        """Start impedance control"""\n        self.impedance_control_active = True\n        self.get_logger().info(\'Started impedance control\')\n\n    def stop_impedance_control(self):\n        """Stop impedance control"""\n        self.impedance_control_active = False\n        self.get_logger().info(\'Stopped impedance control\')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = ForceControlledManipulator()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        print("Shutting down force-controlled manipulator...")\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,o.jsx)(n.h2,{id:"multi-fingered-hand-control",children:"Multi-Fingered Hand Control"}),"\n",(0,o.jsx)(n.h3,{id:"multi-fingered-grasp-control",children:"Multi-Fingered Grasp Control"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import Float64MultiArray\nfrom sensor_msgs.msg import JointState\nfrom geometry_msgs.msg import Point\nfrom std_msgs.msg import String\nimport numpy as np\nimport math\nimport threading\n\nclass MultiFingeredHandController(Node):\n    def __init__(self):\n        super().__init__(\'multi_fingered_hand_controller\')\n\n        # Publishers\n        self.hand_cmd_pub = self.create_publisher(Float64MultiArray, \'/hand_commands\', 10)\n        self.gripper_cmd_pub = self.create_publisher(JointState, \'/gripper_commands\', 10)\n        self.grasp_status_pub = self.create_publisher(String, \'/grasp_status\', 10)\n\n        # Subscribe to grasp planning\n        self.grasp_plan_sub = self.create_subscription(\n            String,\n            \'/grasp_plan\',\n            self.grasp_plan_callback,\n            10\n        )\n\n        # Hand configuration (example: 3-finger hand)\n        self.num_fingers = 3\n        self.finger_joints = 3  # joints per finger\n        self.total_joints = self.num_fingers * self.finger_joints\n\n        # Current hand state\n        self.current_hand_positions = np.zeros(self.total_joints)\n        self.current_hand_velocities = np.zeros(self.total_joints)\n        self.current_hand_efforts = np.zeros(self.total_joints)\n\n        # Grasp parameters\n        self.grasp_types = {\n            \'power\': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0],  # Strong grasp\n            \'precision\': [0.3, 0.3, 0.3, 0.3, 0.3, 0.3],  # Gentle grasp\n            \'cylindrical\': [0.7, 0.7, 0.7, 0.7, 0.7, 0.7],  # Cylindrical grasp\n            \'spherical\': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5]   # Spherical grasp\n        }\n\n        # Threading\n        self.hand_control_lock = threading.Lock()\n\n        self.get_logger().info(\'Multi-Fingered Hand Controller initialized\')\n\n    def grasp_plan_callback(self, msg):\n        """Process grasp plan"""\n        try:\n            grasp_plan = eval(msg.data)  # In practice, use proper deserialization\n            grasp_type = grasp_plan.get(\'type\', \'power\')\n            object_size = grasp_plan.get(\'size\', 0.1)\n\n            # Execute grasp based on plan\n            self.execute_grasp(grasp_type, object_size)\n\n        except Exception as e:\n            self.get_logger().error(f\'Grasp plan callback error: {str(e)}\')\n\n    def execute_grasp(self, grasp_type, object_size):\n        """Execute grasp based on type and object size"""\n        with self.hand_control_lock:\n            if grasp_type in self.grasp_types:\n                # Get basic grasp configuration\n                base_positions = np.array(self.grasp_types[grasp_type])\n\n                # Adjust for object size\n                size_factor = min(1.0, object_size / 0.1)  # Normalize to 10cm object\n                adjusted_positions = base_positions * (1.0 - size_factor * 0.3)  # Smaller objects need more closure\n\n                # Publish hand commands\n                self.publish_hand_commands(adjusted_positions)\n\n                # Publish grasp status\n                status_msg = String()\n                status_msg.data = f"executing_{grasp_type}_grasp_size_{object_size:.3f}m"\n                self.grasp_status_pub.publish(status_msg)\n\n                self.get_logger().info(f\'Executing {grasp_type} grasp for {object_size:.3f}m object\')\n\n    def publish_hand_commands(self, joint_positions):\n        """Publish commands to multi-fingered hand"""\n        # Create Float64MultiArray message\n        cmd_msg = Float64MultiArray()\n        cmd_msg.data = joint_positions.tolist()\n        self.hand_cmd_pub.publish(cmd_msg)\n\n        # Also publish as JointState for compatibility\n        joint_state_msg = JointState()\n        joint_state_msg.header.stamp = self.get_clock().now().to_msg()\n        joint_state_msg.name = [f\'finger_{i}_joint_{j}\' for i in range(self.num_fingers) for j in range(self.finger_joints)]\n        joint_state_msg.position = joint_positions.tolist()\n        joint_state_msg.velocity = [0.0] * len(joint_positions)\n        joint_state_msg.effort = [0.0] * len(joint_positions)\n        self.gripper_cmd_pub.publish(joint_state_msg)\n\n    def execute_predefined_grasp(self, grasp_name):\n        """Execute a predefined grasp type"""\n        if grasp_name in self.grasp_types:\n            positions = np.array(self.grasp_types[grasp_name])\n            self.publish_hand_commands(positions)\n            self.get_logger().info(f\'Executed {grasp_name} grasp\')\n\n    def execute_custom_grasp(self, finger_positions):\n        """Execute custom grasp with specific finger positions"""\n        if len(finger_positions) == self.total_joints:\n            self.publish_hand_commands(np.array(finger_positions))\n            self.get_logger().info(\'Executed custom grasp\')\n\n    def open_hand(self):\n        """Open all fingers"""\n        open_positions = np.zeros(self.total_joints)\n        self.publish_hand_commands(open_positions)\n        self.get_logger().info(\'Opened hand\')\n\n    def close_hand(self):\n        """Close all fingers firmly"""\n        close_positions = np.ones(self.total_joints) * 1.5  # Maximum closure\n        self.publish_hand_commands(close_positions)\n        self.get_logger().info(\'Closed hand firmly\')\n\n    def adjust_grasp_force(self, force_multiplier):\n        """Adjust grasp force by scaling joint positions"""\n        # This is a simplified approach - in reality, force control would be more complex\n        current_positions = self.current_hand_positions.copy()\n        adjusted_positions = current_positions * force_multiplier\n        # Limit to valid joint ranges\n        adjusted_positions = np.clip(adjusted_positions, 0.0, 1.5)\n        self.publish_hand_commands(adjusted_positions)\n        self.get_logger().info(f\'Adjusted grasp force by {force_multiplier:.2f}x\')\n\n    def get_hand_status(self):\n        """Get current hand status"""\n        status = {\n            \'num_fingers\': self.num_fingers,\n            \'joints_per_finger\': self.finger_joints,\n            \'total_joints\': self.total_joints,\n            \'current_positions\': self.current_hand_positions.tolist(),\n            \'grasp_types\': list(self.grasp_types.keys())\n        }\n        return status\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = MultiFingeredHandController()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        print("Shutting down multi-fingered hand controller...")\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,o.jsx)(n.h2,{id:"hands-on-lab-complete-manipulation-system",children:"Hands-on Lab: Complete Manipulation System"}),"\n",(0,o.jsx)(n.p,{children:"In this lab, you'll integrate all manipulation components into a complete system."}),"\n",(0,o.jsx)(n.h3,{id:"step-1-create-the-manipulation-system-launch-file",children:"Step 1: Create the Manipulation System Launch File"}),"\n",(0,o.jsxs)(n.p,{children:["Create ",(0,o.jsx)(n.code,{children:"manipulation_system_launch.py"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\n\nfrom launch import LaunchDescription\nfrom launch.actions import DeclareLaunchArgument, IncludeLaunchDescription\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\nfrom launch.substitutions import LaunchConfiguration, PathJoinSubstitution\nfrom launch_ros.actions import Node\nfrom launch_ros.substitutions import FindPackageShare\n\ndef generate_launch_description():\n    # Declare launch arguments\n    use_sim_time = LaunchConfiguration('use_sim_time', default='true')\n\n    # Manipulation system nodes\n    kinematics = Node(\n        package='ai_robo_learning',\n        executable='manipulation_kinematics',\n        name='manipulation_kinematics',\n        parameters=[{'use_sim_time': use_sim_time}]\n    )\n\n    grasp_planner = Node(\n        package='ai_robo_learning',\n        executable='grasp_planner',\n        name='grasp_planner',\n        parameters=[{'use_sim_time': use_sim_time}]\n    )\n\n    manipulation_planner = Node(\n        package='ai_robo_learning',\n        executable='manipulation_planner',\n        name='manipulation_planner',\n        parameters=[{'use_sim_time': use_sim_time}]\n    )\n\n    force_controller = Node(\n        package='ai_robo_learning',\n        executable='force_controlled_manipulator',\n        name='force_controlled_manipulator',\n        parameters=[{'use_sim_time': use_sim_time}]\n    )\n\n    hand_controller = Node(\n        package='ai_robo_learning',\n        executable='multi_fingered_hand_controller',\n        name='multi_fingered_hand_controller',\n        parameters=[{'use_sim_time': use_sim_time}]\n    )\n\n    # Return launch description\n    ld = LaunchDescription()\n\n    # Add all nodes\n    ld.add_action(kinematics)\n    ld.add_action(grasp_planner)\n    ld.add_action(manipulation_planner)\n    ld.add_action(force_controller)\n    ld.add_action(hand_controller)\n\n    return ld\n"})}),"\n",(0,o.jsx)(n.h3,{id:"step-2-create-the-complete-manipulation-node",children:"Step 2: Create the Complete Manipulation Node"}),"\n",(0,o.jsxs)(n.p,{children:["Create ",(0,o.jsx)(n.code,{children:"complete_manipulation_system.py"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String, Float32\nfrom geometry_msgs.msg import Pose, Point\nfrom sensor_msgs.msg import JointState, WrenchStamped\nfrom action_msgs.msg import GoalStatus\nfrom rclpy.action import ActionServer\nfrom rclpy.executors import MultiThreadedExecutor\nimport numpy as np\nimport math\nimport threading\nimport time\nfrom enum import Enum\n\nclass ManipulationState(Enum):\n    IDLE = 0\n    APPROACHING = 1\n    GRASPING = 2\n    LIFTING = 3\n    MOVING = 4\n    PLACING = 5\n    RETRACTING = 6\n    ERROR = 7\n\nclass CompleteManipulationSystem(Node):\n    def __init__(self):\n        super().__init__(\'complete_manipulation_system\')\n\n        # Subscribe to various inputs\n        self.object_sub = self.create_subscription(\n            String,\n            \'/object_to_manipulate\',\n            self.object_callback,\n            10\n        )\n\n        self.grasp_pose_sub = self.create_subscription(\n            Pose,\n            \'/selected_grasp\',\n            self.grasp_pose_callback,\n            10\n        )\n\n        self.joint_state_sub = self.create_subscription(\n            JointState,\n            \'/joint_states\',\n            self.joint_state_callback,\n            10\n        )\n\n        self.force_sub = self.create_subscription(\n            WrenchStamped,\n            \'/wrench\',\n            self.force_callback,\n            10\n        )\n\n        # Publishers\n        self.joint_cmd_pub = self.create_publisher(JointState, \'/joint_commands\', 10)\n        self.hand_cmd_pub = self.create_publisher(String, \'/hand_commands\', 10)\n        self.status_pub = self.create_publisher(String, \'/manipulation_status\', 10)\n        self.error_pub = self.create_publisher(String, \'/manipulation_error\', 10)\n\n        # Action server for manipulation tasks\n        self._action_server = ActionServer(\n            self,\n            ManipulationAction,\n            \'complete_manipulation\',\n            self.execute_manipulation_callback,\n            goal_callback=self.goal_callback,\n            cancel_callback=self.cancel_callback\n        )\n\n        # System state\n        self.current_object = None\n        self.selected_grasp = None\n        self.current_joints = np.zeros(6)\n        self.current_force = np.array([0.0, 0.0, 0.0])\n        self.manipulation_state = ManipulationState.IDLE\n\n        # Manipulation parameters\n        self.approach_distance = 0.1\n        self.lift_height = 0.2\n        self.retract_distance = 0.1\n        self.max_force_threshold = 20.0  # N\n\n        # Threading\n        self.manipulation_lock = threading.Lock()\n        self.force_monitor_thread = threading.Thread(target=self.force_monitor, daemon=True)\n        self.force_monitor_thread.start()\n\n        # Safety parameters\n        self.safety_enabled = True\n        self.collision_threshold = 0.05  # m\n\n        self.get_logger().info(\'Complete Manipulation System initialized\')\n\n    def object_callback(self, msg):\n        """Process object information"""\n        try:\n            self.current_object = eval(msg.data)  # In practice, use proper deserialization\n            self.get_logger().info(f\'New object: {self.current_object.get("label", "unknown")}\')\n        except Exception as e:\n            self.get_logger().error(f\'Object callback error: {str(e)}\')\n\n    def grasp_pose_callback(self, msg):\n        """Process grasp pose"""\n        self.selected_grasp = msg\n        self.get_logger().info(\'Received grasp pose\')\n\n    def joint_state_callback(self, msg):\n        """Update joint states"""\n        if len(msg.position) >= 6:\n            self.current_joints = np.array(msg.position[:6])\n\n    def force_callback(self, msg):\n        """Update force sensor data"""\n        self.current_force = np.array([\n            msg.wrench.force.x,\n            msg.wrench.force.y,\n            msg.wrench.force.z\n        ])\n\n    def force_monitor(self):\n        """Monitor forces and trigger safety responses"""\n        while rclpy.ok():\n            if self.safety_enabled:\n                force_magnitude = np.linalg.norm(self.current_force)\n\n                if force_magnitude > self.max_force_threshold:\n                    self.trigger_safety_response(f\'Force limit exceeded: {force_magnitude:.2f}N > {self.max_force_threshold}N\')\n\n            time.sleep(0.01)  # 100Hz monitoring\n\n    def goal_callback(self, goal_request):\n        """Handle manipulation goal request"""\n        self.get_logger().info(f\'Received manipulation goal: {goal_request.action}\')\n        return GoalResponse.ACCEPT\n\n    def cancel_callback(self, goal_handle):\n        """Handle manipulation goal cancellation"""\n        self.get_logger().info(\'Received manipulation goal cancellation\')\n        return CancelResponse.ACCEPT\n\n    async def execute_manipulation_callback(self, goal_handle):\n        """Execute complete manipulation task"""\n        self.get_logger().info(\'Executing complete manipulation task\')\n\n        feedback_msg = ManipulationAction.Feedback()\n        result = ManipulationAction.Result()\n\n        with self.manipulation_lock:\n            try:\n                action = goal_handle.request.action\n                target_pose = goal_handle.request.target_pose\n\n                if action == "pick_and_place":\n                    success = await self.execute_pick_and_place_task(target_pose, feedback_msg)\n                elif action == "grasp":\n                    success = await self.execute_grasp_task(target_pose, feedback_msg)\n                elif action == "move_object":\n                    success = await self.execute_move_object_task(target_pose, feedback_msg)\n                else:\n                    self.get_logger().error(f\'Unknown manipulation action: {action}\')\n                    success = False\n\n                if success:\n                    goal_handle.succeed()\n                    result.success = True\n                    result.message = f\'Successfully completed {action} action\'\n                else:\n                    goal_handle.abort()\n                    result.success = False\n                    result.message = f\'Failed to complete {action} action\'\n\n            except Exception as e:\n                self.get_logger().error(f\'Manipulation execution error: {str(e)}\')\n                goal_handle.abort()\n                result.success = False\n                result.message = f\'Execution error: {str(e)}\'\n\n        return result\n\n    async def execute_pick_and_place_task(self, target_pose, feedback_msg):\n        """Execute complete pick and place task"""\n        self.get_logger().info(\'Executing pick and place task\')\n\n        # Step 1: Approach object\n        self.manipulation_state = ManipulationState.APPROACHING\n        feedback_msg.current_stage = "approaching_object"\n        feedback_msg.progress = 0.0\n        goal_handle.publish_feedback(feedback_msg)\n\n        approach_pose = self.calculate_approach_pose(self.selected_grasp)\n        if not await self.move_to_pose(approach_pose, feedback_msg, "approaching_object"):\n            return False\n\n        # Step 2: Grasp object\n        self.manipulation_state = ManipulationState.GRASPING\n        feedback_msg.current_stage = "grasping_object"\n        goal_handle.publish_feedback(feedback_msg)\n\n        if not await self.execute_grasp(feedback_msg):\n            return False\n\n        # Step 3: Lift object\n        self.manipulation_state = ManipulationState.LIFTING\n        feedback_msg.current_stage = "lifting_object"\n        goal_handle.publish_feedback(feedback_msg)\n\n        lift_pose = self.calculate_lift_pose(self.selected_grasp)\n        if not await self.move_to_pose(lift_pose, feedback_msg, "lifting_object"):\n            return False\n\n        # Step 4: Move to target location\n        self.manipulation_state = ManipulationState.MOVING\n        feedback_msg.current_stage = "moving_to_target"\n        goal_handle.publish_feedback(feedback_msg)\n\n        if not await self.move_to_pose(target_pose, feedback_msg, "moving_to_target"):\n            return False\n\n        # Step 5: Place object\n        self.manipulation_state = ManipulationState.PLACING\n        feedback_msg.current_stage = "placing_object"\n        goal_handle.publish_feedback(feedback_msg)\n\n        if not await self.execute_place(feedback_msg):\n            return False\n\n        # Step 6: Retract\n        self.manipulation_state = ManipulationState.RETRACTING\n        feedback_msg.current_stage = "retracting"\n        goal_handle.publish_feedback(feedback_msg)\n\n        retract_pose = self.calculate_retreat_pose(target_pose)\n        if not await self.move_to_pose(retract_pose, feedback_msg, "retracting"):\n            return False\n\n        self.manipulation_state = ManipulationState.IDLE\n        self.get_logger().info(\'Pick and place task completed successfully\')\n        return True\n\n    async def execute_grasp_task(self, target_pose, feedback_msg):\n        """Execute grasp task"""\n        self.get_logger().info(\'Executing grasp task\')\n\n        # Approach\n        approach_pose = self.calculate_approach_pose(target_pose)\n        if not await self.move_to_pose(approach_pose, feedback_msg, "approaching"):\n            return False\n\n        # Grasp\n        if not await self.execute_grasp(feedback_msg):\n            return False\n\n        self.get_logger().info(\'Grasp task completed successfully\')\n        return True\n\n    async def execute_move_object_task(self, target_pose, feedback_msg):\n        """Execute move object task"""\n        self.get_logger().info(\'Executing move object task\')\n\n        # Move to target pose\n        if not await self.move_to_pose(target_pose, feedback_msg, "moving_object"):\n            return False\n\n        self.get_logger().info(\'Move object task completed successfully\')\n        return True\n\n    def calculate_approach_pose(self, target_pose):\n        """Calculate approach pose"""\n        approach_pose = Pose()\n        approach_pose.position = target_pose.position\n        approach_pose.orientation = target_pose.orientation\n\n        # Move back along approach direction\n        approach_direction = self.calculate_approach_vector(target_pose)\n        approach_pose.position.x -= approach_direction[0] * self.approach_distance\n        approach_pose.position.y -= approach_direction[1] * self.approach_distance\n        approach_pose.position.z -= approach_direction[2] * self.approach_distance\n\n        return approach_pose\n\n    def calculate_lift_pose(self, grasp_pose):\n        """Calculate lift pose"""\n        lift_pose = Pose()\n        lift_pose.position = grasp_pose.position\n        lift_pose.orientation = grasp_pose.orientation\n\n        # Move up\n        lift_pose.position.z += self.lift_height\n\n        return lift_pose\n\n    def calculate_retreat_pose(self, place_pose):\n        """Calculate retreat pose"""\n        retreat_pose = Pose()\n        retreat_pose.position = place_pose.position\n        retreat_pose.orientation = place_pose.orientation\n\n        # Move up\n        retreat_pose.position.z += self.retract_distance\n\n        return retreat_pose\n\n    def calculate_approach_vector(self, target_pose):\n        """Calculate approach vector"""\n        # For top-down grasp, approach from above\n        return [0, 0, -1]\n\n    async def move_to_pose(self, target_pose, feedback_msg, stage):\n        """Move end effector to target pose"""\n        try:\n            # In a real system, this would solve IK and move the arm\n            # For simulation, just log the movement\n            self.get_logger().info(f\'Moving to pose for {stage}\')\n\n            # Simulate movement progress\n            for i in range(10):\n                feedback_msg.progress = (i + 1) / 10.0\n                goal_handle.publish_feedback(feedback_msg)\n                await rclpy.sleep(0.1)\n\n            return True\n\n        except Exception as e:\n            self.get_logger().error(f\'Move to pose error: {str(e)}\')\n            return False\n\n    async def execute_grasp(self, feedback_msg):\n        """Execute grasping action"""\n        try:\n            self.get_logger().info(\'Executing grasp\')\n\n            # Publish hand command to close gripper\n            hand_cmd = String()\n            hand_cmd.data = "close_gripper"\n            self.hand_cmd_pub.publish(hand_cmd)\n\n            # Simulate grasp time\n            await rclpy.sleep(0.5)\n\n            # Check if grasp was successful (simplified)\n            force_magnitude = np.linalg.norm(self.current_force)\n            if force_magnitude > 1.0:  # Some contact detected\n                self.get_logger().info(\'Grasp successful\')\n                return True\n            else:\n                self.get_logger().warn(\'Grasp may have failed - no contact detected\')\n                return False\n\n        except Exception as e:\n            self.get_logger().error(f\'Grasp execution error: {str(e)}\')\n            return False\n\n    async def execute_place(self, feedback_msg):\n        """Execute placing action"""\n        try:\n            self.get_logger().info(\'Executing place\')\n\n            # Publish hand command to open gripper\n            hand_cmd = String()\n            hand_cmd.data = "open_gripper"\n            self.hand_cmd_pub.publish(hand_cmd)\n\n            # Simulate release time\n            await rclpy.sleep(0.5)\n\n            self.get_logger().info(\'Place completed\')\n            return True\n\n        except Exception as e:\n            self.get_logger().error(f\'Place execution error: {str(e)}\')\n            return False\n\n    def trigger_safety_response(self, error_msg):\n        """Trigger safety response for excessive forces"""\n        self.get_logger().error(f\'Safety response triggered: {error_msg}\')\n\n        # Publish error\n        error_message = String()\n        error_message.data = error_msg\n        self.error_pub.publish(error_message)\n\n        # Stop all motion (in a real system, send stop commands)\n        self.manipulation_state = ManipulationState.ERROR\n\n        # Publish emergency stop (simplified)\n        stop_cmd = JointState()\n        stop_cmd.position = [0.0] * len(self.current_joints)\n        self.joint_cmd_pub.publish(stop_cmd)\n\n    def publish_status(self, status):\n        """Publish manipulation status"""\n        status_msg = String()\n        status_msg.data = f"{self.manipulation_state.name}:{status}"\n        self.status_pub.publish(status_msg)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = CompleteManipulationSystem()\n\n    try:\n        executor = MultiThreadedExecutor()\n        rclpy.spin(node, executor=executor)\n    except KeyboardInterrupt:\n        print("Shutting down complete manipulation system...")\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,o.jsx)(n.h3,{id:"step-3-test-the-manipulation-system",children:"Step 3: Test the Manipulation System"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"Make sure you have the required dependencies:"}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"pip3 install numpy scipy\n"})}),"\n",(0,o.jsxs)(n.ol,{start:"2",children:["\n",(0,o.jsx)(n.li,{children:"Run the complete manipulation system:"}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"python3 complete_manipulation_system.py\n"})}),"\n",(0,o.jsxs)(n.ol,{start:"3",children:["\n",(0,o.jsx)(n.li,{children:"Test with manipulation commands:"}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"# Send a manipulation goal using action interface\n# Or use direct commands to test individual components\n"})}),"\n",(0,o.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Safety First"}),": Always implement safety checks and force limits"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Force Control"}),": Use force feedback for compliant manipulation"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Grasp Planning"}),": Plan grasps considering object properties and robot capabilities"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Kinematics"}),": Ensure proper forward and inverse kinematics"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Calibration"}),": Calibrate sensors and actuators for accurate manipulation"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Validation"}),": Validate grasps before execution"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Error Handling"}),": Implement robust error recovery"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Testing"}),": Test extensively with various objects and scenarios"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,o.jsx)(n.p,{children:"After completing this chapter, you'll be ready to learn about the capstone project in Chapter 6, where you'll integrate all the components learned throughout the course into a complete humanoid robot system."})]})}function _(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(p,{...e})}):p(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>i});var a=t(6540);const o={},s=a.createContext(o);function r(e){const n=a.useContext(s);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),a.createElement(s.Provider,{value:n},e.children)}}}]);