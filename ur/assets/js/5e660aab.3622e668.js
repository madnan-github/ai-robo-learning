"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[5],{5050:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Module 1: Physical AI & Humanoid Robotics","items":[{"type":"link","href":"/ai-robo-learning/ur/docs/module-1/chapter-1/introduction","label":"Introduction to Physical AI & Humanoid Robotics","docId":"module-1/chapter-1/introduction","unlisted":false},{"type":"link","href":"/ai-robo-learning/ur/docs/module-1/chapter-2/nodes-architecture","label":"ROS 2 Nodes and Architecture","docId":"module-1/chapter-2/nodes-architecture","unlisted":false},{"type":"link","href":"/ai-robo-learning/ur/docs/module-1/chapter-3/topics-message-passing","label":"Topics and Message Passing","docId":"module-1/chapter-3/topics-message-passing","unlisted":false},{"type":"link","href":"/ai-robo-learning/ur/docs/module-1/chapter-4/services-actions","label":"Services and Actions","docId":"module-1/chapter-4/services-actions","unlisted":false},{"type":"link","href":"/ai-robo-learning/ur/docs/module-1/chapter-5/rclpy-integration","label":"rclpy and Python Integration","docId":"module-1/chapter-5/rclpy-integration","unlisted":false},{"type":"link","href":"/ai-robo-learning/ur/docs/module-1/chapter-6/urdf-humanoids","label":"URDF for Humanoid Robots","docId":"module-1/chapter-6/urdf-humanoids","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2: ROS 2 Fundamentals","items":[{"type":"link","href":"/ai-robo-learning/ur/docs/module-2/chapter-1/ros2-fundamentals","label":"ROS 2 Fundamentals","docId":"module-2/chapter-1/ros2-fundamentals","unlisted":false},{"type":"link","href":"/ai-robo-learning/ur/docs/module-2/chapter-2/gazebo-physics","label":"Gazebo Physics Simulation","docId":"module-2/chapter-2/gazebo-physics","unlisted":false},{"type":"link","href":"/ai-robo-learning/ur/docs/module-2/chapter-3/robot-models-gazebo","label":"Creating Robot Models in Gazebo","docId":"module-2/chapter-3/robot-models-gazebo","unlisted":false},{"type":"link","href":"/ai-robo-learning/ur/docs/module-2/chapter-4/sensor-simulation","label":"Sensor Simulation","docId":"module-2/chapter-4/sensor-simulation","unlisted":false},{"type":"link","href":"/ai-robo-learning/ur/docs/module-2/chapter-5/unity-integration","label":"Unity Integration","docId":"module-2/chapter-5/unity-integration","unlisted":false},{"type":"link","href":"/ai-robo-learning/ur/docs/module-2/chapter-6/environment-building","label":"Environment Building","docId":"module-2/chapter-6/environment-building","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3: Simulation with Gazebo","items":[{"type":"link","href":"/ai-robo-learning/ur/docs/module-3/chapter-1/simulation-basics","label":"Simulation Basics with Gazebo","docId":"module-3/chapter-1/simulation-basics","unlisted":false},{"type":"link","href":"/ai-robo-learning/ur/docs/module-3/chapter-2/isaac-sim","label":"NVIDIA Isaac Sim","docId":"module-3/chapter-2/isaac-sim","unlisted":false},{"type":"link","href":"/ai-robo-learning/ur/docs/module-3/chapter-3/isaac-ros-vslam","label":"Isaac ROS and VSLAM","docId":"module-3/chapter-3/isaac-ros-vslam","unlisted":false},{"type":"link","href":"/ai-robo-learning/ur/docs/module-3/chapter-4/navigation-nav2","label":"Navigation with Nav2","docId":"module-3/chapter-4/navigation-nav2","unlisted":false},{"type":"link","href":"/ai-robo-learning/ur/docs/module-3/chapter-5/path-planning-humanoids","label":"Path Planning for Humanoids","docId":"module-3/chapter-5/path-planning-humanoids","unlisted":false},{"type":"link","href":"/ai-robo-learning/ur/docs/module-3/chapter-6/perception-systems","label":"Perception Systems","docId":"module-3/chapter-6/perception-systems","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4: AI Integration","items":[{"type":"link","href":"/ai-robo-learning/ur/docs/module-4/chapter-1/ai-integration","label":"AI Integration in Robotics","docId":"module-4/chapter-1/ai-integration","unlisted":false},{"type":"link","href":"/ai-robo-learning/ur/docs/module-4/chapter-2/voice-command-processing","label":"Voice Command Processing","docId":"module-4/chapter-2/voice-command-processing","unlisted":false},{"type":"link","href":"/ai-robo-learning/ur/docs/module-4/chapter-3/cognitive-planning-llms","label":"Cognitive Planning with LLMs","docId":"module-4/chapter-3/cognitive-planning-llms","unlisted":false},{"type":"link","href":"/ai-robo-learning/ur/docs/module-4/chapter-4/computer-vision-robotics","label":"Computer Vision for Robotics","docId":"module-4/chapter-4/computer-vision-robotics","unlisted":false},{"type":"link","href":"/ai-robo-learning/ur/docs/module-4/chapter-5/object-manipulation","label":"Object Manipulation","docId":"module-4/chapter-5/object-manipulation","unlisted":false},{"type":"link","href":"/ai-robo-learning/ur/docs/module-4/chapter-6/capstone-project","label":"Capstone Project - Autonomous Humanoid Robot","docId":"module-4/chapter-6/capstone-project","unlisted":false}],"collapsed":true,"collapsible":true}]},"docs":{"intro":{"id":"intro","title":"Welcome","description":"This is the introduction page for the Physical AI & Humanoid Robotics textbook. This textbook enables self-learners to build and command simulated autonomous humanoid robots using ROS 2, Gazebo, NVIDIA Isaac, and Vision-Language-Action (VLA) pipelines."},"module-1/chapter-1/introduction":{"id":"module-1/chapter-1/introduction","title":"Introduction to Physical AI & Humanoid Robotics","description":"Welcome to the exciting world of Physical AI and Humanoid Robotics! This module provides the foundation for understanding how to build and command simulated autonomous humanoid robots.","sidebar":"tutorialSidebar"},"module-1/chapter-2/nodes-architecture":{"id":"module-1/chapter-2/nodes-architecture","title":"ROS 2 Nodes and Architecture","description":"This chapter explores the fundamental building blocks of ROS 2 systems - nodes and their architecture. Understanding nodes is crucial for creating distributed robotic applications.","sidebar":"tutorialSidebar"},"module-1/chapter-3/topics-message-passing":{"id":"module-1/chapter-3/topics-message-passing","title":"Topics and Message Passing","description":"This chapter covers the publisher-subscriber communication pattern in ROS 2, which is the most common way for nodes to exchange data in robotic systems.","sidebar":"tutorialSidebar"},"module-1/chapter-4/services-actions":{"id":"module-1/chapter-4/services-actions","title":"Services and Actions","description":"This chapter covers two important communication patterns in ROS 2: services for synchronous request-response communication and actions for long-running tasks with feedback.","sidebar":"tutorialSidebar"},"module-1/chapter-5/rclpy-integration":{"id":"module-1/chapter-5/rclpy-integration","title":"rclpy and Python Integration","description":"This chapter focuses on integrating Python-based AI agents with ROS 2 systems using rclpy, the Python client library for ROS 2. You\'ll learn how to bridge AI algorithms with robotic control systems.","sidebar":"tutorialSidebar"},"module-1/chapter-6/urdf-humanoids":{"id":"module-1/chapter-6/urdf-humanoids","title":"URDF for Humanoid Robots","description":"This chapter covers the Unified Robot Description Format (URDF), which is essential for describing humanoid robots in ROS 2. You\'ll learn how to create detailed robot models that can be used in simulation and control.","sidebar":"tutorialSidebar"},"module-2/chapter-1/ros2-fundamentals":{"id":"module-2/chapter-1/ros2-fundamentals","title":"ROS 2 Fundamentals","description":"This module covers the essential concepts of ROS 2 (Robot Operating System), which forms the backbone of most robotic applications.","sidebar":"tutorialSidebar"},"module-2/chapter-2/gazebo-physics":{"id":"module-2/chapter-2/gazebo-physics","title":"Gazebo Physics Simulation","description":"This chapter covers the fundamentals of physics simulation in Gazebo, including how to create realistic environments for humanoid robots with proper physics properties.","sidebar":"tutorialSidebar"},"module-2/chapter-3/robot-models-gazebo":{"id":"module-2/chapter-3/robot-models-gazebo","title":"Creating Robot Models in Gazebo","description":"This chapter focuses on adapting your URDF models for Gazebo simulation, including adding Gazebo-specific plugins, sensors, and physical properties to create realistic robot simulations.","sidebar":"tutorialSidebar"},"module-2/chapter-4/sensor-simulation":{"id":"module-2/chapter-4/sensor-simulation","title":"Sensor Simulation","description":"This chapter covers the simulation of various sensors in Gazebo, including LiDAR, cameras, depth sensors, and IMUs, which are essential for humanoid robot perception and navigation.","sidebar":"tutorialSidebar"},"module-2/chapter-5/unity-integration":{"id":"module-2/chapter-5/unity-integration","title":"Unity Integration","description":"This chapter covers integrating Unity for high-fidelity rendering and human-robot interaction in simulation. Unity provides photorealistic environments and advanced graphics capabilities that complement Gazebo\'s physics simulation.","sidebar":"tutorialSidebar"},"module-2/chapter-6/environment-building":{"id":"module-2/chapter-6/environment-building","title":"Environment Building","description":"This chapter covers creating and customizing simulation environments for humanoid robots, including indoor and outdoor scenarios, obstacle courses, and complex multi-room environments.","sidebar":"tutorialSidebar"},"module-3/chapter-1/simulation-basics":{"id":"module-3/chapter-1/simulation-basics","title":"Simulation Basics with Gazebo","description":"This module introduces you to robot simulation using Gazebo, a powerful 3D simulation environment widely used in robotics research and development.","sidebar":"tutorialSidebar"},"module-3/chapter-2/isaac-sim":{"id":"module-3/chapter-2/isaac-sim","title":"NVIDIA Isaac Sim","description":"This chapter covers NVIDIA Isaac Sim, a comprehensive robotics simulation platform that provides photorealistic simulation, synthetic data generation, and AI training capabilities for humanoid robots and other robotic systems.","sidebar":"tutorialSidebar"},"module-3/chapter-3/isaac-ros-vslam":{"id":"module-3/chapter-3/isaac-ros-vslam","title":"Isaac ROS and VSLAM","description":"This chapter covers Isaac ROS, NVIDIA\'s hardware-accelerated perception pipeline, and Visual SLAM (VSLAM) for humanoid robots. You\'ll learn how to leverage GPU acceleration for real-time computer vision and navigation.","sidebar":"tutorialSidebar"},"module-3/chapter-4/navigation-nav2":{"id":"module-3/chapter-4/navigation-nav2","title":"Navigation with Nav2","description":"This chapter covers the Navigation2 (Nav2) framework, which provides advanced path planning and navigation capabilities for humanoid robots, including support for complex environments and dynamic obstacle avoidance.","sidebar":"tutorialSidebar"},"module-3/chapter-5/path-planning-humanoids":{"id":"module-3/chapter-5/path-planning-humanoids","title":"Path Planning for Humanoids","description":"This chapter focuses on path planning specifically designed for bipedal humanoid robots, addressing the unique challenges of walking locomotion, balance, and stability that differentiate humanoid navigation from wheeled robots.","sidebar":"tutorialSidebar"},"module-3/chapter-6/perception-systems":{"id":"module-3/chapter-6/perception-systems","title":"Perception Systems","description":"This chapter covers advanced perception systems for humanoid robots, including computer vision, depth sensing, object recognition, and environment understanding that enable autonomous navigation and interaction.","sidebar":"tutorialSidebar"},"module-4/chapter-1/ai-integration":{"id":"module-4/chapter-1/ai-integration","title":"AI Integration in Robotics","description":"This module explores how artificial intelligence techniques can be integrated into robotic systems, including Vision-Language-Action (VLA) pipelines.","sidebar":"tutorialSidebar"},"module-4/chapter-2/voice-command-processing":{"id":"module-4/chapter-2/voice-command-processing","title":"Voice Command Processing","description":"This chapter covers voice command processing for humanoid robots, including speech recognition, natural language understanding, and voice-to-action conversion using OpenAI Whisper and other speech processing technologies.","sidebar":"tutorialSidebar"},"module-4/chapter-3/cognitive-planning-llms":{"id":"module-4/chapter-3/cognitive-planning-llms","title":"Cognitive Planning with LLMs","description":"This chapter covers using Large Language Models (LLMs) for cognitive planning in robotics, enabling robots to understand complex natural language commands and translate them into executable action sequences.","sidebar":"tutorialSidebar"},"module-4/chapter-4/computer-vision-robotics":{"id":"module-4/chapter-4/computer-vision-robotics","title":"Computer Vision for Robotics","description":"This chapter covers computer vision techniques specifically designed for robotics applications, including object detection, tracking, recognition, and 3D scene understanding that enable robots to perceive and interact with their environment.","sidebar":"tutorialSidebar"},"module-4/chapter-5/object-manipulation":{"id":"module-4/chapter-5/object-manipulation","title":"Object Manipulation","description":"This chapter covers robotic object manipulation, including grasping, picking, placing, and manipulation planning that enables humanoid robots to interact with objects in their environment.","sidebar":"tutorialSidebar"},"module-4/chapter-6/capstone-project":{"id":"module-4/chapter-6/capstone-project","title":"Capstone Project - Autonomous Humanoid Robot","description":"This capstone chapter integrates all the concepts learned throughout the course to build a complete autonomous humanoid robot system capable of navigating, perceiving, and manipulating objects in a real environment.","sidebar":"tutorialSidebar"}}}}')}}]);