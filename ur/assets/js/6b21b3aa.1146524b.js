"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[339],{1403:(n,e,a)=>{a.r(e),a.d(e,{assets:()=>l,contentTitle:()=>i,default:()=>p,frontMatter:()=>r,metadata:()=>t,toc:()=>_});const t=JSON.parse('{"id":"module-3/chapter-4/navigation-nav2","title":"Navigation with Nav2","description":"This chapter covers the Navigation2 (Nav2) framework, which provides advanced path planning and navigation capabilities for humanoid robots, including support for complex environments and dynamic obstacle avoidance.","source":"@site/docs/module-3/chapter-4/navigation-nav2.md","sourceDirName":"module-3/chapter-4","slug":"/module-3/chapter-4/navigation-nav2","permalink":"/ai-robo-learning/ur/docs/module-3/chapter-4/navigation-nav2","draft":false,"unlisted":false,"editUrl":"https://github.com/madnan-github/ai-robo-learning/docs/module-3/chapter-4/navigation-nav2.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"Navigation with Nav2"},"sidebar":"tutorialSidebar","previous":{"title":"Isaac ROS and VSLAM","permalink":"/ai-robo-learning/ur/docs/module-3/chapter-3/isaac-ros-vslam"},"next":{"title":"Path Planning for Humanoids","permalink":"/ai-robo-learning/ur/docs/module-3/chapter-5/path-planning-humanoids"}}');var s=a(4848),o=a(8453);const r={sidebar_position:4,title:"Navigation with Nav2"},i="Navigation with Nav2",l={},_=[{value:"What You&#39;ll Learn",id:"what-youll-learn",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Understanding Nav2 Architecture",id:"understanding-nav2-architecture",level:2},{value:"Nav2 Component Flow",id:"nav2-component-flow",level:3},{value:"Nav2 Configuration for Humanoid Robots",id:"nav2-configuration-for-humanoid-robots",level:2},{value:"Basic Nav2 Configuration",id:"basic-nav2-configuration",level:3},{value:"Path Planning Algorithms",id:"path-planning-algorithms",level:2},{value:"Nav2 Path Planner Node",id:"nav2-path-planner-node",level:3},{value:"Costmap Configuration for Humanoid Robots",id:"costmap-configuration-for-humanoid-robots",level:2},{value:"Advanced Costmap Configuration",id:"advanced-costmap-configuration",level:3},{value:"Behavior Trees for Navigation",id:"behavior-trees-for-navigation",level:2},{value:"Nav2 Behavior Tree Configuration",id:"nav2-behavior-tree-configuration",level:3},{value:"Custom Behavior Tree Node for Humanoid Navigation",id:"custom-behavior-tree-node-for-humanoid-navigation",level:3},{value:"Dynamic Obstacle Avoidance",id:"dynamic-obstacle-avoidance",level:2},{value:"Dynamic Obstacle Detection and Avoidance",id:"dynamic-obstacle-detection-and-avoidance",level:3},{value:"Hands-on Lab: Complete Navigation System",id:"hands-on-lab-complete-navigation-system",level:2},{value:"Step 1: Create the Navigation System Launch File",id:"step-1-create-the-navigation-system-launch-file",level:3},{value:"Step 2: Create the Complete Navigation Node",id:"step-2-create-the-complete-navigation-node",level:3},{value:"Step 3: Test the Navigation System",id:"step-3-test-the-navigation-system",level:3},{value:"Tuning and Optimization",id:"tuning-and-optimization",level:2},{value:"Navigation Parameter Tuning",id:"navigation-parameter-tuning",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"Next Steps",id:"next-steps",level:2}];function c(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"navigation-with-nav2",children:"Navigation with Nav2"})}),"\n",(0,s.jsx)(e.p,{children:"This chapter covers the Navigation2 (Nav2) framework, which provides advanced path planning and navigation capabilities for humanoid robots, including support for complex environments and dynamic obstacle avoidance."}),"\n",(0,s.jsx)(e.h2,{id:"what-youll-learn",children:"What You'll Learn"}),"\n",(0,s.jsx)(e.p,{children:"In this chapter, you'll explore:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Nav2 architecture and components"}),"\n",(0,s.jsx)(e.li,{children:"Costmap configuration for humanoid robots"}),"\n",(0,s.jsx)(e.li,{children:"Path planning algorithms (A*, Dijkstra, DWA, etc.)"}),"\n",(0,s.jsx)(e.li,{children:"Dynamic obstacle avoidance"}),"\n",(0,s.jsx)(e.li,{children:"Behavior trees for navigation"}),"\n",(0,s.jsx)(e.li,{children:"Integration with VSLAM and perception systems"}),"\n",(0,s.jsx)(e.li,{children:"Navigation tuning and optimization"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Completion of Module 1-3, Chapters 1-3"}),"\n",(0,s.jsx)(e.li,{children:"ROS 2 Humble installed"}),"\n",(0,s.jsx)(e.li,{children:"Understanding of coordinate frames and TF"}),"\n",(0,s.jsx)(e.li,{children:"Basic knowledge of path planning concepts"}),"\n",(0,s.jsx)(e.li,{children:"Experience with sensor integration"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"understanding-nav2-architecture",children:"Understanding Nav2 Architecture"}),"\n",(0,s.jsx)(e.p,{children:"Nav2 is built on a component-based architecture with the following main components:"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Navigation System"}),": Coordinates the overall navigation process"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Path Planner"}),": Generates global paths from start to goal"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Controller"}),": Tracks the global path with local adjustments"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Recovery"}),": Handles navigation failures and stuck situations"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Costmap"}),": Maintains obstacle information for planning"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"nav2-component-flow",children:"Nav2 Component Flow"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"[Goal Request] --\x3e [Global Planner] --\x3e [Path] --\x3e [Controller] --\x3e [Commands]\n                     |                    |           |\n                  [Costmap]          [Costmap]   [Local Planner]\n                     |                    |           |\n                [Sensor Data]      [Sensor Data] [Sensor Data]\n"})}),"\n",(0,s.jsx)(e.h2,{id:"nav2-configuration-for-humanoid-robots",children:"Nav2 Configuration for Humanoid Robots"}),"\n",(0,s.jsx)(e.h3,{id:"basic-nav2-configuration",children:"Basic Nav2 Configuration"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-yaml",children:'# nav2_params.yaml\namcl:\n  ros__parameters:\n    use_sim_time: True\n    alpha1: 0.2\n    alpha2: 0.2\n    alpha3: 0.2\n    alpha4: 0.2\n    alpha5: 0.2\n    base_frame_id: "base_link"\n    beam_skip_distance: 0.5\n    beam_skip_error_threshold: 0.9\n    beam_skip_threshold: 0.3\n    do_beamskip: false\n    global_frame_id: "map"\n    lambda_short: 0.1\n    laser_likelihood_max_dist: 2.0\n    laser_max_range: 100.0\n    laser_min_range: -1.0\n    laser_model_type: "likelihood_field"\n    max_beams: 60\n    max_particles: 2000\n    min_particles: 500\n    odom_frame_id: "odom"\n    pf_err: 0.05\n    pf_z: 0.99\n    recovery_alpha_fast: 0.0\n    recovery_alpha_slow: 0.0\n    resample_interval: 1\n    robot_model_type: "nav2_amcl::DifferentialMotionModel"\n    save_pose_rate: 0.5\n    sigma_hit: 0.2\n    tf_broadcast: true\n    transform_tolerance: 1.0\n    update_min_a: 0.2\n    update_min_d: 0.25\n    z_hit: 0.5\n    z_max: 0.05\n    z_rand: 0.5\n    z_short: 0.05\n\namcl_map_client:\n  ros__parameters:\n    use_sim_time: True\n\namcl_rclcpp_node:\n  ros__parameters:\n    use_sim_time: True\n\nbt_navigator:\n  ros__parameters:\n    use_sim_time: True\n    global_frame: "map"\n    robot_base_frame: "base_link"\n    odom_topic: "/odom"\n    bt_loop_duration: 10\n    default_server_timeout: 20\n    enable_groot_monitoring: True\n    groot_zmq_publisher_port: 1666\n    groot_zmq_server_port: 1667\n    # Specify the path to the Behavior Tree XML file\n    default_nav_through_poses_bt_xml: "navigate_w_replanning_and_recovery.xml"\n    default_nav_to_pose_bt_xml: "navigate_w_replanning_and_recovery.xml"\n    plugin_lib_names:\n    - nav2_compute_path_to_pose_action_bt_node\n    - nav2_compute_path_through_poses_action_bt_node\n    - nav2_follow_path_action_bt_node\n    - nav2_back_up_action_bt_node\n    - nav2_spin_action_bt_node\n    - nav2_wait_action_bt_node\n    - nav2_clear_costmap_service_bt_node\n    - nav2_is_stuck_condition_bt_node\n    - nav2_are_error_codes_active_condition_bt_node\n    - nav2_is_path_valid_condition_bt_node\n    - nav2_is_battery_low_condition_bt_node\n    - nav2_external_condition\n    - nav2_recovery_node_bt_node\n    - nav2_pipeline_sequence_bt_node\n    - nav2_round_robin_node_bt_node\n    - nav2_transform_available_condition_bt_node\n    - nav2_time_expired_condition_bt_node\n    - nav2_distance_traveled_condition_bt_node\n    - nav2_speed_condition_bt_node\n\nbt_navigator_rclcpp_node:\n  ros__parameters:\n    use_sim_time: True\n\ncontroller_server:\n  ros__parameters:\n    use_sim_time: True\n    controller_frequency: 20.0\n    min_x_velocity_threshold: 0.001\n    min_y_velocity_threshold: 0.5\n    min_theta_velocity_threshold: 0.001\n    progress_checker_plugin: "progress_checker"\n    goal_checker_plugin: "goal_checker"\n    controller_plugins: ["FollowPath"]\n\n    # Humanoid-specific controller configuration\n    FollowPath:\n      plugin: "nav2_mppi_controller::MPPIController"\n      time_steps: 50\n      model_dt: 0.05\n      batch_size: 1000\n      vx_std: 0.2\n      vy_std: 0.2\n      wz_std: 0.3\n      vx_max: 0.5\n      vx_min: -0.2\n      vy_max: 0.5\n      wz_max: 1.0\n      goal_dist_tol: 0.25\n      goal_angle_tol: 0.25\n      xy_goal_tolerance: 0.25\n      yaw_goal_tolerance: 0.25\n      trans_stopped_velocity: 0.25\n      rot_stopped_velocity: 0.25\n      simulation_mode: false\n      model_plugin_name: "omni"\n      critic_names: ["BaseObstacleCritic", "GoalCritic", "PathAlignCritic", "PathFollowCritic", "PathProgressCritic", "PreferForwardCritic"]\n\n      BaseObstacleCritic:\n        scale: 2.0\n        sensor_topic: "/scan"\n      GoalCritic:\n        scale: 2.0\n      PathAlignCritic:\n        scale: 3.2\n        offset: 2.0\n      PathFollowCritic:\n        scale: 3.0\n      PathProgressCritic:\n        scale: 4.0\n      PreferForwardCritic:\n        scale: 1.0\n\ncontroller_server_rclcpp_node:\n  ros__parameters:\n    use_sim_time: True\n\nlocal_costmap:\n  local_costmap:\n    ros__parameters:\n      update_frequency: 5.0\n      publish_frequency: 2.0\n      global_frame: "odom"\n      robot_base_frame: "base_link"\n      use_sim_time: True\n      rolling_window: true\n      width: 6\n      height: 6\n      resolution: 0.05\n      # Humanoid-specific footprint\n      footprint: "[[-0.3, -0.2], [-0.3, 0.2], [0.3, 0.2], [0.3, -0.2]]"\n      plugins: ["voxel_layer", "inflation_layer"]\n      inflation_layer:\n        plugin: "nav2_costmap_2d::InflationLayer"\n        cost_scaling_factor: 3.0\n        inflation_radius: 0.55\n      voxel_layer:\n        plugin: "nav2_costmap_2d::VoxelLayer"\n        enabled: True\n        publish_voxel_map: True\n        origin_z: 0.0\n        z_resolution: 0.2\n        z_voxels: 10\n        max_obstacle_height: 2.0\n        mark_threshold: 0\n        observation_sources: scan\n        scan:\n          topic: /scan\n          max_obstacle_height: 2.0\n          clearing: True\n          marking: True\n          data_type: "LaserScan"\n          raytrace_max_range: 3.0\n          raytrace_min_range: 0.0\n          obstacle_max_range: 2.5\n          obstacle_min_range: 0.0\n  local_costmap_client:\n    ros__parameters:\n      use_sim_time: True\n  local_costmap_rclcpp_node:\n    ros__parameters:\n      use_sim_time: True\n\nglobal_costmap:\n  global_costmap:\n    ros__parameters:\n      update_frequency: 1.0\n      publish_frequency: 0.5\n      global_frame: "map"\n      robot_base_frame: "base_link"\n      use_sim_time: True\n      robot_radius: 0.3\n      resolution: 0.05\n      track_unknown_space: true\n      plugins: ["static_layer", "obstacle_layer", "inflation_layer"]\n      obstacle_layer:\n        plugin: "nav2_costmap_2d::ObstacleLayer"\n        enabled: True\n        observation_sources: scan\n        scan:\n          topic: /scan\n          max_obstacle_height: 2.0\n          clearing: True\n          marking: True\n          data_type: "LaserScan"\n          raytrace_max_range: 3.0\n          raytrace_min_range: 0.0\n          obstacle_max_range: 2.5\n          obstacle_min_range: 0.0\n      static_layer:\n        plugin: "nav2_costmap_2d::StaticLayer"\n        map_subscribe_transient_local: True\n      inflation_layer:\n        plugin: "nav2_costmap_2d::InflationLayer"\n        cost_scaling_factor: 3.0\n        inflation_radius: 0.55\n  global_costmap_client:\n    ros__parameters:\n      use_sim_time: True\n  global_costmap_rclcpp_node:\n    ros__parameters:\n      use_sim_time: True\n\nmap_server:\n  ros__parameters:\n    use_sim_time: True\n    yaml_filename: "turtlebot3_world.yaml"\n\nmap_saver:\n  ros__parameters:\n    use_sim_time: True\n    save_map_timeout: 5.0\n    free_thresh_default: 0.25\n    occupied_thresh_default: 0.65\n\nplanner_server:\n  ros__parameters:\n    expected_planner_frequency: 20.0\n    use_sim_time: True\n    planner_plugins: ["GridBased"]\n    GridBased:\n      plugin: "nav2_navfn_planner::NavfnPlanner"\n      tolerance: 0.5\n      use_astar: false\n      allow_unknown: true\n\nplanner_server_rclcpp_node:\n  ros__parameters:\n    use_sim_time: True\n\nrecoveries_server:\n  ros__parameters:\n    costmap_topic: "local_costmap/costmap_raw"\n    footprint_topic: "local_costmap/published_footprint"\n    cycle_frequency: 10.0\n    recovery_plugins: ["spin", "backup", "wait"]\n    spin:\n      plugin: "nav2_recoveries::Spin"\n      sim_frequency: 5\n      angle_thresh: 0.0\n      time_allowance: 10\n    backup:\n      plugin: "nav2_recoveries::BackUp"\n      sim_frequency: 5\n      distance: 0.15\n      speed: 0.025\n      time_allowance: 10\n    wait:\n      plugin: "nav2_recoveries::Wait"\n      sim_frequency: 5\n      time: 5\n'})}),"\n",(0,s.jsx)(e.h2,{id:"path-planning-algorithms",children:"Path Planning Algorithms"}),"\n",(0,s.jsx)(e.h3,{id:"nav2-path-planner-node",children:"Nav2 Path Planner Node"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.node import Node\nfrom nav_msgs.msg import Path, OccupancyGrid\nfrom geometry_msgs.msg import PoseStamped, Point\nfrom visualization_msgs.msg import Marker, MarkerArray\nimport numpy as np\nfrom scipy.spatial import KDTree\nimport heapq\n\nclass Nav2PathPlanner(Node):\n    def __init__(self):\n        super().__init__(\'nav2_path_planner\')\n\n        # Subscribe to costmap and goal\n        self.costmap_sub = self.create_subscription(\n            OccupancyGrid,\n            \'/global_costmap/costmap\',\n            self.costmap_callback,\n            10\n        )\n\n        self.goal_sub = self.create_subscription(\n            PoseStamped,\n            \'/goal_pose\',\n            self.goal_callback,\n            10\n        )\n\n        # Publisher for planned path\n        self.path_pub = self.create_publisher(Path, \'/plan\', 10)\n        self.marker_pub = self.create_publisher(MarkerArray, \'/path_markers\', 10)\n\n        # Store costmap data\n        self.costmap = None\n        self.map_resolution = 0.05\n        self.map_origin = [0, 0]\n        self.current_goal = None\n\n        self.get_logger().info(\'Nav2 Path Planner initialized\')\n\n    def costmap_callback(self, msg):\n        """Process incoming costmap"""\n        self.costmap = np.array(msg.data).reshape(msg.info.height, msg.info.width)\n        self.map_resolution = msg.info.resolution\n        self.map_origin = [msg.info.origin.position.x, msg.info.origin.position.y]\n\n    def goal_callback(self, msg):\n        """Process incoming goal and plan path"""\n        if self.costmap is not None:\n            self.current_goal = msg\n            self.plan_path()\n\n    def plan_path(self):\n        """Plan path using A* algorithm"""\n        if self.costmap is None or self.current_goal is None:\n            return\n\n        # Convert goal position to map coordinates\n        goal_x = int((self.current_goal.pose.position.x - self.map_origin[0]) / self.map_resolution)\n        goal_y = int((self.current_goal.pose.position.y - self.map_origin[1]) / self.map_resolution)\n\n        # Get robot position (simplified - in real system, use AMCL)\n        robot_x, robot_y = self.get_robot_position()\n\n        # Run A* path planning\n        path = self.a_star_path(robot_x, robot_y, goal_x, goal_y)\n\n        if path:\n            # Convert path to ROS Path message\n            path_msg = Path()\n            path_msg.header.stamp = self.get_clock().now().to_msg()\n            path_msg.header.frame_id = "map"\n\n            for point in path:\n                pose_stamped = PoseStamped()\n                pose_stamped.header.frame_id = "map"\n                pose_stamped.pose.position.x = point[0] * self.map_resolution + self.map_origin[0]\n                pose_stamped.pose.position.y = point[1] * self.map_resolution + self.map_origin[1]\n                pose_stamped.pose.position.z = 0.0\n                pose_stamped.pose.orientation.w = 1.0\n                path_msg.poses.append(pose_stamped)\n\n            # Publish path\n            self.path_pub.publish(path_msg)\n\n            # Publish visualization markers\n            self.publish_path_markers(path_msg)\n\n            self.get_logger().info(f\'Path planned with {len(path)} waypoints\')\n\n    def a_star_path(self, start_x, start_y, goal_x, goal_y):\n        """A* path planning algorithm"""\n        if (start_x < 0 or start_x >= self.costmap.shape[1] or\n            start_y < 0 or start_y >= self.costmap.shape[0] or\n            goal_x < 0 or goal_x >= self.costmap.shape[1] or\n            goal_y < 0 or goal_y >= self.costmap.shape[0]):\n            return None\n\n        # Check if start or goal is in obstacle\n        if self.costmap[start_y, start_x] > 50 or self.costmap[goal_y, goal_x] > 50:\n            return None\n\n        # A* algorithm implementation\n        open_set = [(0, (start_x, start_y))]\n        came_from = {}\n        g_score = {(start_x, start_y): 0}\n        f_score = {(start_x, start_y): self.heuristic(start_x, start_y, goal_x, goal_y)}\n\n        while open_set:\n            current = heapq.heappop(open_set)[1]\n\n            if current == (goal_x, goal_y):\n                # Reconstruct path\n                path = [current]\n                while current in came_from:\n                    current = came_from[current]\n                    path.append(current)\n                path.reverse()\n                return path\n\n            for neighbor in self.get_neighbors(current[0], current[1]):\n                if neighbor[0] < 0 or neighbor[0] >= self.costmap.shape[1] or \\\n                   neighbor[1] < 0 or neighbor[1] >= self.costmap.shape[0]:\n                    continue\n\n                # Skip if obstacle\n                if self.costmap[neighbor[1], neighbor[0]] > 50:\n                    continue\n\n                tentative_g_score = g_score[current] + self.distance(current, neighbor)\n\n                if neighbor not in g_score or tentative_g_score < g_score[neighbor]:\n                    came_from[neighbor] = current\n                    g_score[neighbor] = tentative_g_score\n                    f_score[neighbor] = tentative_g_score + self.heuristic(neighbor[0], neighbor[1], goal_x, goal_y)\n                    heapq.heappush(open_set, (f_score[neighbor], neighbor))\n\n        return None  # No path found\n\n    def heuristic(self, x1, y1, x2, y2):\n        """Heuristic function for A* (Euclidean distance)"""\n        return np.sqrt((x1 - x2)**2 + (y1 - y2)**2)\n\n    def distance(self, pos1, pos2):\n        """Distance between two positions"""\n        return np.sqrt((pos1[0] - pos2[0])**2 + (pos1[1] - pos2[1])**2)\n\n    def get_neighbors(self, x, y):\n        """Get 8-connected neighbors"""\n        neighbors = []\n        for dx in [-1, 0, 1]:\n            for dy in [-1, 0, 1]:\n                if dx == 0 and dy == 0:\n                    continue\n                neighbors.append((x + dx, y + dy))\n        return neighbors\n\n    def get_robot_position(self):\n        """Get robot position (simplified - in real system, use TF or AMCL)"""\n        # For simulation, return a fixed position\n        # In real system, use TF to get robot pose in map frame\n        return 10, 10  # Example coordinates\n\n    def publish_path_markers(self, path_msg):\n        """Publish visualization markers for path"""\n        marker_array = MarkerArray()\n\n        # Create line strip marker for path\n        path_marker = Marker()\n        path_marker.header = path_msg.header\n        path_marker.ns = "navigation_path"\n        path_marker.id = 0\n        path_marker.type = Marker.LINE_STRIP\n        path_marker.action = Marker.ADD\n\n        path_marker.pose.orientation.w = 1.0\n        path_marker.scale.x = 0.05  # Line width\n\n        path_marker.color.r = 0.0\n        path_marker.color.g = 1.0\n        path_marker.color.b = 0.0\n        path_marker.color.a = 1.0\n\n        for pose_stamped in path_msg.poses:\n            point = Point()\n            point.x = pose_stamped.pose.position.x\n            point.y = pose_stamped.pose.position.y\n            point.z = pose_stamped.pose.position.z\n            path_marker.points.append(point)\n\n        marker_array.markers.append(path_marker)\n\n        # Create start and goal markers\n        if len(path_msg.poses) >= 2:\n            start_marker = Marker()\n            start_marker.header = path_msg.header\n            start_marker.ns = "navigation_start"\n            start_marker.id = 1\n            start_marker.type = Marker.SPHERE\n            start_marker.action = Marker.ADD\n\n            start_marker.pose = path_msg.poses[0].pose\n            start_marker.scale.x = 0.3\n            start_marker.scale.y = 0.3\n            start_marker.scale.z = 0.3\n\n            start_marker.color.r = 0.0\n            start_marker.color.g = 0.0\n            start_marker.color.b = 1.0\n            start_marker.color.a = 1.0\n\n            marker_array.markers.append(start_marker)\n\n            goal_marker = Marker()\n            goal_marker.header = path_msg.header\n            goal_marker.ns = "navigation_goal"\n            goal_marker.id = 2\n            goal_marker.type = Marker.SPHERE\n            goal_marker.action = Marker.ADD\n\n            goal_marker.pose = path_msg.poses[-1].pose\n            goal_marker.scale.x = 0.3\n            goal_marker.scale.y = 0.3\n            goal_marker.scale.z = 0.3\n\n            goal_marker.color.r = 1.0\n            goal_marker.color.g = 0.0\n            goal_marker.color.b = 0.0\n            goal_marker.color.a = 1.0\n\n            marker_array.markers.append(goal_marker)\n\n        self.marker_pub.publish(marker_array)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = Nav2PathPlanner()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,s.jsx)(e.h2,{id:"costmap-configuration-for-humanoid-robots",children:"Costmap Configuration for Humanoid Robots"}),"\n",(0,s.jsx)(e.h3,{id:"advanced-costmap-configuration",children:"Advanced Costmap Configuration"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.node import Node\nfrom nav_msgs.msg import OccupancyGrid\nfrom sensor_msgs.msg import LaserScan, PointCloud2\nfrom geometry_msgs.msg import PointStamped\nimport numpy as np\nimport cv2\nfrom scipy.ndimage import binary_dilation, binary_erosion\n\nclass HumanoidCostmapGenerator(Node):\n    def __init__(self):\n        super().__init__(\'humanoid_costmap_generator\')\n\n        # Subscribe to sensor data\n        self.laser_sub = self.create_subscription(\n            LaserScan,\n            \'/scan\',\n            self.laser_callback,\n            10\n        )\n\n        self.pointcloud_sub = self.create_subscription(\n            PointCloud2,\n            \'/points2\',\n            self.pointcloud_callback,\n            10\n        )\n\n        # Publisher for costmap\n        self.costmap_pub = self.create_publisher(OccupancyGrid, \'/custom_costmap\', 10)\n\n        # Costmap parameters\n        self.map_width = 20  # meters\n        self.map_height = 20  # meters\n        self.resolution = 0.1  # meters per cell\n        self.map_size_x = int(self.map_width / self.resolution)\n        self.map_size_y = int(self.map_height / self.resolution)\n\n        # Robot-specific parameters for humanoid\n        self.robot_radius = 0.3  # meters\n        self.robot_height = 1.5  # meters (for 3D considerations)\n\n        # Initialize costmap\n        self.costmap = np.zeros((self.map_size_y, self.map_size_x), dtype=np.int8)\n\n        # Robot position (simplified - in real system, use TF)\n        self.robot_x = self.map_size_x // 2\n        self.robot_y = self.map_size_y // 2\n\n        self.get_logger().info(\'Humanoid Costmap Generator initialized\')\n\n    def laser_callback(self, msg):\n        """Process laser scan data and update costmap"""\n        # Convert laser scan to occupancy grid\n        ranges = np.array(msg.ranges)\n        angles = np.array([msg.angle_min + i * msg.angle_increment for i in range(len(ranges))])\n\n        # Filter out invalid ranges\n        valid_mask = (ranges >= msg.range_min) & (ranges <= msg.range_max) & (~np.isnan(ranges)) & (~np.isinf(ranges))\n        valid_ranges = ranges[valid_mask]\n        valid_angles = angles[valid_mask]\n\n        # Convert to Cartesian coordinates relative to robot\n        x_points = valid_ranges * np.cos(valid_angles)\n        y_points = valid_ranges * np.sin(valid_angles)\n\n        # Convert to map coordinates\n        map_x = (x_points / self.resolution + self.robot_x).astype(int)\n        map_y = (y_points / self.resolution + self.robot_y).astype(int)\n\n        # Filter points within map bounds\n        valid_points = (map_x >= 0) & (map_x < self.map_size_x) & \\\n                      (map_y >= 0) & (map_y < self.map_size_y)\n\n        map_x = map_x[valid_points]\n        map_y = map_y[valid_points]\n\n        # Update costmap with obstacle information\n        self.update_costmap_obstacles(map_x, map_y)\n\n        # Publish updated costmap\n        self.publish_costmap()\n\n    def pointcloud_callback(self, msg):\n        """Process point cloud data and update costmap"""\n        # In a real system, this would convert PointCloud2 to numpy array\n        # For this example, we\'ll simulate the process\n        self.get_logger().info(\'Point cloud received (simulation)\')\n\n    def update_costmap_obstacles(self, obstacle_x, obstacle_y):\n        """Update costmap with obstacle information"""\n        # Clear previous obstacle information (set to -1 for unknown)\n        self.costmap[:] = -1\n\n        # Mark obstacles\n        for x, y in zip(obstacle_x, obstacle_y):\n            if 0 <= x < self.map_size_x and 0 <= y < self.map_size_y:\n                # Mark as obstacle (100)\n                self.costmap[y, x] = 100\n\n                # Apply inflation based on humanoid robot size\n                self.inflate_obstacle(x, y, int(self.robot_radius / self.resolution))\n\n    def inflate_obstacle(self, center_x, center_y, inflation_radius):\n        """Inflate obstacles to account for robot size"""\n        # Create a circular mask for inflation\n        y, x = np.ogrid[:self.map_size_y, :self.map_size_x]\n        mask = (x - center_x)**2 + (y - center_y)**2 <= inflation_radius**2\n\n        # Apply inflation to costmap\n        self.costmap[mask & (self.costmap != 100)] = 99  # High cost but not maximum\n\n    def publish_costmap(self):\n        """Publish costmap as OccupancyGrid message"""\n        costmap_msg = OccupancyGrid()\n        costmap_msg.header.stamp = self.get_clock().now().to_msg()\n        costmap_msg.header.frame_id = "map"\n\n        costmap_msg.info.resolution = self.resolution\n        costmap_msg.info.width = self.map_size_x\n        costmap_msg.info.height = self.map_size_y\n        costmap_msg.info.origin.position.x = -self.map_width / 2.0\n        costmap_msg.info.origin.position.y = -self.map_height / 2.0\n        costmap_msg.info.origin.position.z = 0.0\n        costmap_msg.info.origin.orientation.w = 1.0\n\n        # Flatten costmap array and convert to list\n        costmap_data = self.costmap.flatten()\n        costmap_msg.data = costmap_data.tolist()\n\n        self.costmap_pub.publish(costmap_msg)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = HumanoidCostmapGenerator()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,s.jsx)(e.h2,{id:"behavior-trees-for-navigation",children:"Behavior Trees for Navigation"}),"\n",(0,s.jsx)(e.h3,{id:"nav2-behavior-tree-configuration",children:"Nav2 Behavior Tree Configuration"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-xml",children:'\x3c!-- navigate_w_replanning_and_recovery.xml --\x3e\n<root main_tree_to_execute="MainTree">\n    <BehaviorTree ID="MainTree">\n        <PipelineSequence name="NavigateWithReplanning">\n            <RateController hz="1.0">\n                <ComputePathToPose goal="{goal}" path="{path}" planner_id="GridBased"/>\n            </RateController>\n            <RecoveryNode number_of_retries="6" name="NavigateRecovery">\n                <PipelineSequence name="NavigateRecoveryActions">\n                    <ClearEntireCostmap name="ClearGlobalCostmap-1" service_name="global_costmap/clear_entirely_global_costmap"/>\n                    <ClearEntireCostmap name="ClearLocalCostmap-1" service_name="local_costmap/clear_entirely_local_costmap"/>\n                    <Spin name="Spin" spin_dist="1.57"/>\n                </PipelineSequence>\n            </RecoveryNode>\n        </PipelineSequence>\n        <ReactiveSequence name="FollowPathWithReplanning">\n            <IsPathValid path="{path}"/>\n            <FollowPath path="{path}" controller_id="FollowPath"/>\n        </ReactiveSequence>\n    </BehaviorTree>\n</root>\n'})}),"\n",(0,s.jsx)(e.h3,{id:"custom-behavior-tree-node-for-humanoid-navigation",children:"Custom Behavior Tree Node for Humanoid Navigation"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.node import Node\nfrom rclpy.action import ActionServer\nfrom rclpy.executors import MultiThreadedExecutor\nfrom geometry_msgs.msg import PoseStamped\nfrom nav2_msgs.action import NavigateToPose\nfrom std_msgs.msg import Bool\nimport time\n\nclass HumanoidNavigateToPoseServer(Node):\n    def __init__(self):\n        super().__init__(\'humanoid_navigate_to_pose_server\')\n\n        # Create action server\n        self._action_server = ActionServer(\n            self,\n            NavigateToPose,\n            \'navigate_to_pose\',\n            self.execute_callback\n        )\n\n        # Publisher for navigation status\n        self.nav_status_pub = self.create_publisher(Bool, \'/navigation_active\', 10)\n\n        self.get_logger().info(\'Humanoid Navigate To Pose Server initialized\')\n\n    def execute_callback(self, goal_handle):\n        """Execute navigation goal"""\n        self.get_logger().info(\'Received navigation goal\')\n\n        # Publish navigation active status\n        status_msg = Bool()\n        status_msg.data = True\n        self.nav_status_pub.publish(status_msg)\n\n        # Get goal pose\n        goal_pose = goal_handle.request.pose\n\n        # Simulate navigation execution\n        feedback_msg = NavigateToPose.Feedback()\n        result = NavigateToPose.Result()\n\n        # Navigation simulation\n        current_pose = self.get_current_pose()\n        distance = self.calculate_distance(current_pose, goal_pose)\n\n        # Simulate navigation steps\n        for i in range(10):  # Simulate 10 steps\n            if goal_handle.is_cancel_requested:\n                goal_handle.canceled()\n                self.get_logger().info(\'Goal canceled\')\n                status_msg.data = False\n                self.nav_status_pub.publish(status_msg)\n                return result\n\n            # Update feedback\n            feedback_msg.current_pose = current_pose\n            feedback_msg.distance_remaining = distance * (10 - i) / 10.0\n            goal_handle.publish_feedback(feedback_msg)\n\n            # Simulate movement\n            time.sleep(0.5)\n\n        # Navigation completed\n        goal_handle.succeed()\n        result.result = True\n        self.get_logger().info(\'Navigation completed successfully\')\n\n        # Publish navigation inactive status\n        status_msg.data = False\n        self.nav_status_pub.publish(status_msg)\n\n        return result\n\n    def get_current_pose(self):\n        """Get current robot pose (simplified)"""\n        from geometry_msgs.msg import Pose\n        pose = Pose()\n        pose.position.x = 0.0\n        pose.position.y = 0.0\n        pose.position.z = 0.0\n        pose.orientation.w = 1.0\n        return pose\n\n    def calculate_distance(self, pose1, pose2):\n        """Calculate Euclidean distance between two poses"""\n        dx = pose2.position.x - pose1.position.x\n        dy = pose2.position.y - pose1.position.y\n        dz = pose2.position.z - pose1.position.z\n        return (dx**2 + dy**2 + dz**2)**0.5\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = HumanoidNavigateToPoseServer()\n\n    try:\n        executor = MultiThreadedExecutor()\n        rclpy.spin(node, executor=executor)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,s.jsx)(e.h2,{id:"dynamic-obstacle-avoidance",children:"Dynamic Obstacle Avoidance"}),"\n",(0,s.jsx)(e.h3,{id:"dynamic-obstacle-detection-and-avoidance",children:"Dynamic Obstacle Detection and Avoidance"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan\nfrom geometry_msgs.msg import Twist, PoseStamped\nfrom nav_msgs.msg import Path\nfrom visualization_msgs.msg import MarkerArray\nimport numpy as np\nfrom collections import deque\nimport math\n\nclass DynamicObstacleAvoider(Node):\n    def __init__(self):\n        super().__init__(\'dynamic_obstacle_avoider\')\n\n        # Subscribe to laser scan and path\n        self.scan_sub = self.create_subscription(\n            LaserScan,\n            \'/scan\',\n            self.scan_callback,\n            10\n        )\n\n        self.path_sub = self.create_subscription(\n            Path,\n            \'/plan\',\n            self.path_callback,\n            10\n        )\n\n        # Publisher for velocity commands\n        self.cmd_vel_pub = self.create_publisher(Twist, \'/cmd_vel\', 10)\n        self.avoidance_marker_pub = self.create_publisher(MarkerArray, \'/avoidance_markers\', 10)\n\n        # Store path and current position\n        self.current_path = None\n        self.path_index = 0\n        self.obstacle_buffer = deque(maxlen=10)  # Store recent obstacle data\n\n        # Robot parameters\n        self.robot_radius = 0.3  # meters\n        self.safe_distance = 0.5  # meters\n        self.max_linear_speed = 0.5  # m/s\n        self.max_angular_speed = 1.0  # rad/s\n\n        # Navigation state\n        self.is_avoiding = False\n        self.avoidance_start_time = None\n\n        self.get_logger().info(\'Dynamic Obstacle Avoider initialized\')\n\n    def path_callback(self, msg):\n        """Store the current navigation path"""\n        self.current_path = msg\n        self.path_index = 0  # Reset path index\n\n    def scan_callback(self, msg):\n        """Process laser scan for obstacle detection and avoidance"""\n        try:\n            # Convert scan to Cartesian points\n            angles = np.array([msg.angle_min + i * msg.angle_increment for i in range(len(msg.ranges))])\n            ranges = np.array(msg.ranges)\n\n            # Filter valid ranges\n            valid_mask = (ranges >= msg.range_min) & (ranges <= msg.range_max) & (~np.isnan(ranges)) & (~np.isinf(ranges))\n            valid_ranges = ranges[valid_mask]\n            valid_angles = angles[valid_mask]\n\n            # Convert to Cartesian coordinates\n            x_points = valid_ranges * np.cos(valid_angles)\n            y_points = valid_ranges * np.sin(valid_angles)\n\n            # Detect obstacles in front of robot\n            front_mask = (np.abs(y_points) < 0.5) & (x_points > 0) & (x_points < 2.0)  # Front half-plane\n            front_obstacles_x = x_points[front_mask]\n            front_obstacles_y = y_points[front_mask]\n\n            if len(front_obstacles_x) > 0:\n                # Check if obstacles are too close\n                min_distance = np.min(np.sqrt(front_obstacles_x**2 + front_obstacles_y**2))\n\n                if min_distance < self.safe_distance:\n                    self.get_logger().info(f\'Obstacle detected at {min_distance:.2f}m, initiating avoidance\')\n                    cmd_vel = self.avoid_obstacle(front_obstacles_x, front_obstacles_y)\n                    self.cmd_vel_pub.publish(cmd_vel)\n                    self.is_avoiding = True\n                    self.avoidance_start_time = self.get_clock().now().nanoseconds / 1e9\n                    return\n                else:\n                    self.is_avoiding = False\n            else:\n                self.is_avoiding = False\n\n            # If not avoiding, follow path\n            if not self.is_avoiding:\n                cmd_vel = self.follow_path()\n                self.cmd_vel_pub.publish(cmd_vel)\n\n        except Exception as e:\n            self.get_logger().error(f\'Error in scan processing: {str(e)}\')\n\n    def avoid_obstacle(self, obs_x, obs_y):\n        """Generate velocity commands to avoid obstacles"""\n        cmd_vel = Twist()\n\n        # Calculate obstacle centroid\n        centroid_x = np.mean(obs_x)\n        centroid_y = np.mean(obs_y)\n\n        # Determine avoidance direction (prefer left if obstacle is on the right, vice versa)\n        if centroid_y > 0:  # Obstacle on the right\n            cmd_vel.angular.z = self.max_angular_speed  # Turn left\n            cmd_vel.linear.x = self.max_linear_speed * 0.3  # Slow down\n        else:  # Obstacle on the left\n            cmd_vel.angular.z = -self.max_angular_speed  # Turn right\n            cmd_vel.linear.x = self.max_linear_speed * 0.3  # Slow down\n\n        # Limit angular velocity based on proximity\n        distance = np.sqrt(centroid_x**2 + centroid_y**2)\n        cmd_vel.angular.z *= (distance / self.safe_distance)  # Reduce turn as we get closer\n\n        return cmd_vel\n\n    def follow_path(self):\n        """Follow the planned path"""\n        cmd_vel = Twist()\n\n        if self.current_path is None or len(self.current_path.poses) == 0:\n            return cmd_vel\n\n        # Get current robot position (simplified - in real system, use TF)\n        robot_x, robot_y = 0.0, 0.0  # Placeholder\n\n        # Find next waypoint to follow\n        target_x = self.current_path.poses[self.path_index].pose.position.x\n        target_y = self.current_path.poses[self.path_index].pose.position.y\n\n        # Calculate distance to target\n        dist_to_target = math.sqrt((target_x - robot_x)**2 + (target_y - robot_y)**2)\n\n        # If close to current target, move to next waypoint\n        if dist_to_target < 0.3 and self.path_index < len(self.current_path.poses) - 1:\n            self.path_index += 1\n            target_x = self.current_path.poses[self.path_index].pose.position.x\n            target_y = self.current_path.poses[self.path_index].pose.position.y\n\n        # Calculate direction to target\n        angle_to_target = math.atan2(target_y - robot_y, target_x - robot_x)\n\n        # Simple proportional controller\n        cmd_vel.linear.x = min(self.max_linear_speed, dist_to_target)\n        cmd_vel.angular.z = angle_to_target * 1.0  # Proportional gain\n\n        # Limit angular velocity\n        cmd_vel.angular.z = max(-self.max_angular_speed, min(self.max_angular_speed, cmd_vel.angular.z))\n\n        return cmd_vel\n\n    def publish_avoidance_markers(self):\n        """Publish visualization markers for avoidance behavior"""\n        marker_array = MarkerArray()\n\n        # Create markers for dynamic obstacles\n        # Implementation would go here\n\n        self.avoidance_marker_pub.publish(marker_array)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = DynamicObstacleAvoider()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,s.jsx)(e.h2,{id:"hands-on-lab-complete-navigation-system",children:"Hands-on Lab: Complete Navigation System"}),"\n",(0,s.jsx)(e.p,{children:"In this lab, you'll create a complete navigation system that integrates path planning, obstacle avoidance, and humanoid-specific considerations."}),"\n",(0,s.jsx)(e.h3,{id:"step-1-create-the-navigation-system-launch-file",children:"Step 1: Create the Navigation System Launch File"}),"\n",(0,s.jsxs)(e.p,{children:["Create ",(0,s.jsx)(e.code,{children:"nav2_humanoid_launch.py"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"#!/usr/bin/env python3\n\nfrom launch import LaunchDescription\nfrom launch.actions import DeclareLaunchArgument, IncludeLaunchDescription\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\nfrom launch.substitutions import LaunchConfiguration, PathJoinSubstitution\nfrom launch_ros.actions import Node\nfrom launch_ros.substitutions import FindPackageShare\nfrom launch.conditions import IfCondition\nfrom launch.substitutions import PythonExpression\n\ndef generate_launch_description():\n    # Declare launch arguments\n    use_sim_time = LaunchConfiguration('use_sim_time', default='true')\n    autostart = LaunchConfiguration('autostart', default='true')\n    params_file = LaunchConfiguration('params_file', default='nav2_params.yaml')\n\n    # Include Nav2 main launch file\n    nav2_launch = IncludeLaunchDescription(\n        PythonLaunchDescriptionSource([\n            PathJoinSubstitution([\n                FindPackageShare('nav2_bringup'),\n                'launch',\n                'navigation_launch.py'\n            ])\n        ]),\n        launch_arguments={\n            'use_sim_time': use_sim_time,\n            'autostart': autostart,\n            'params_file': params_file\n        }.items()\n    )\n\n    # Humanoid-specific navigation nodes\n    humanoid_path_planner = Node(\n        package='ai_robo_learning',\n        executable='nav2_path_planner',\n        name='humanoid_path_planner',\n        parameters=[{'use_sim_time': use_sim_time}],\n        remappings=[\n            ('/plan', '/humanoid_plan'),\n            ('/goal_pose', '/goal_pose')\n        ]\n    )\n\n    humanoid_costmap_generator = Node(\n        package='ai_robo_learning',\n        executable='humanoid_costmap_generator',\n        name='humanoid_costmap_generator',\n        parameters=[{'use_sim_time': use_sim_time}],\n        remappings=[\n            ('/scan', '/scan'),\n            ('/custom_costmap', '/humanoid_costmap')\n        ]\n    )\n\n    dynamic_obstacle_avoider = Node(\n        package='ai_robo_learning',\n        executable='dynamic_obstacle_avoider',\n        name='dynamic_obstacle_avoider',\n        parameters=[{'use_sim_time': use_sim_time}],\n        remappings=[\n            ('/scan', '/scan'),\n            ('/plan', '/humanoid_plan'),\n            ('/cmd_vel', '/cmd_vel')\n        ]\n    )\n\n    # Return launch description\n    ld = LaunchDescription()\n\n    # Add all actions\n    ld.add_action(nav2_launch)\n    ld.add_action(humanoid_path_planner)\n    ld.add_action(humanoid_costmap_generator)\n    ld.add_action(dynamic_obstacle_avoider)\n\n    return ld\n"})}),"\n",(0,s.jsx)(e.h3,{id:"step-2-create-the-complete-navigation-node",children:"Step 2: Create the Complete Navigation Node"}),"\n",(0,s.jsxs)(e.p,{children:["Create ",(0,s.jsx)(e.code,{children:"complete_navigation_system.py"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan, Imu\nfrom nav_msgs.msg import Odometry, Path\nfrom geometry_msgs.msg import Twist, PoseStamped, Point\nfrom visualization_msgs.msg import MarkerArray\nfrom tf2_ros import TransformListener, Buffer\nfrom std_msgs.msg import Bool\nimport numpy as np\nfrom collections import deque\nimport math\nimport threading\n\nclass CompleteNavigationSystem(Node):\n    def __init__(self):\n        super().__init__(\'complete_navigation_system\')\n\n        # Subscribe to sensors\n        self.scan_sub = self.create_subscription(\n            LaserScan,\n            \'/scan\',\n            self.scan_callback,\n            10\n        )\n\n        self.odom_sub = self.create_subscription(\n            Odometry,\n            \'/odom\',\n            self.odom_callback,\n            10\n        )\n\n        self.imu_sub = self.create_subscription(\n            Imu,\n            \'/imu/data\',\n            self.imu_callback,\n            10\n        )\n\n        self.goal_sub = self.create_subscription(\n            PoseStamped,\n            \'/goal_pose\',\n            self.goal_callback,\n            10\n        )\n\n        self.path_sub = self.create_subscription(\n            Path,\n            \'/plan\',\n            self.path_callback,\n            10\n        )\n\n        # Publishers\n        self.cmd_vel_pub = self.create_publisher(Twist, \'/cmd_vel\', 10)\n        self.status_pub = self.create_publisher(Bool, \'/navigation_active\', 10)\n        self.marker_pub = self.create_publisher(MarkerArray, \'/nav_markers\', 10)\n\n        # TF listener\n        self.tf_buffer = Buffer()\n        self.tf_listener = TransformListener(self.tf_buffer, self)\n\n        # Navigation state\n        self.current_path = None\n        self.path_index = 0\n        self.current_goal = None\n        self.robot_pose = None\n        self.imu_data = None\n        self.navigation_active = False\n\n        # Robot parameters\n        self.robot_radius = 0.3  # meters\n        self.safe_distance = 0.5  # meters\n        self.max_linear_speed = 0.3  # m/s (slower for humanoid stability)\n        self.max_angular_speed = 0.5  # rad/s\n        self.min_linear_speed = 0.1  # minimum speed to maintain stability\n\n        # Obstacle avoidance\n        self.obstacle_buffer = deque(maxlen=20)\n        self.avoidance_active = False\n        self.last_avoidance_time = 0\n\n        # Threading lock\n        self.nav_lock = threading.Lock()\n\n        self.get_logger().info(\'Complete Navigation System initialized\')\n\n    def goal_callback(self, msg):\n        """Handle navigation goal"""\n        with self.nav_lock:\n            self.current_goal = msg\n            self.navigation_active = True\n            self.path_index = 0\n            self.avoidance_active = False\n\n            # Publish navigation status\n            status_msg = Bool()\n            status_msg.data = True\n            self.status_pub.publish(status_msg)\n\n            self.get_logger().info(f\'Navigation goal received: ({msg.pose.position.x:.2f}, {msg.pose.position.y:.2f})\')\n\n    def path_callback(self, msg):\n        """Store navigation path"""\n        with self.nav_lock:\n            self.current_path = msg\n            self.path_index = 0\n\n    def odom_callback(self, msg):\n        """Update robot pose from odometry"""\n        with self.nav_lock:\n            self.robot_pose = msg.pose.pose\n\n    def imu_callback(self, msg):\n        """Store IMU data"""\n        with self.nav_lock:\n            self.imu_data = msg\n\n    def scan_callback(self, msg):\n        """Process laser scan for navigation"""\n        with self.nav_lock:\n            if not self.navigation_active:\n                return\n\n            # Convert scan to obstacle points\n            angles = np.array([msg.angle_min + i * msg.angle_increment for i in range(len(msg.ranges))])\n            ranges = np.array(msg.ranges)\n\n            # Filter valid ranges\n            valid_mask = (ranges >= msg.range_min) & (ranges <= msg.range_max) & (~np.isnan(ranges)) & (~np.isinf(ranges))\n            valid_ranges = ranges[valid_mask]\n            valid_angles = angles[valid_mask]\n\n            # Convert to Cartesian coordinates\n            x_points = valid_ranges * np.cos(valid_angles)\n            y_points = valid_ranges * np.sin(valid_angles)\n\n            # Check for obstacles in robot\'s path\n            obstacle_detected = self.check_path_obstacles(x_points, y_points)\n\n            if obstacle_detected:\n                # Generate avoidance command\n                cmd_vel = self.generate_avoidance_command(x_points, y_points)\n                self.avoidance_active = True\n                self.last_avoidance_time = self.get_clock().now().nanoseconds / 1e9\n            else:\n                # Follow path normally\n                cmd_vel = self.follow_path_command()\n                self.avoidance_active = False\n\n            # Publish command\n            self.cmd_vel_pub.publish(cmd_vel)\n\n    def check_path_obstacles(self, obs_x, obs_y):\n        """Check if obstacles are blocking the current path"""\n        if self.current_path is None or self.robot_pose is None:\n            return False\n\n        # Get current position\n        robot_x = self.robot_pose.position.x\n        robot_y = self.robot_pose.position.y\n\n        # Check next few waypoints\n        check_distance = 1.0  # meters ahead to check\n        path_points = []\n\n        for i in range(self.path_index, min(self.path_index + 10, len(self.current_path.poses))):\n            pose = self.current_path.poses[i].pose.position\n            path_points.append((pose.x, pose.y))\n\n        # Check if any obstacles are within safe distance of path\n        for obs_x_single, obs_y_single in zip(obs_x, obs_y):\n            # Convert obstacle to map coordinates relative to robot\n            world_obs_x = robot_x + obs_x_single\n            world_obs_y = robot_y + obs_y_single\n\n            # Check distance to path\n            for path_x, path_y in path_points:\n                dist = math.sqrt((world_obs_x - path_x)**2 + (world_obs_y - path_y)**2)\n                if dist < self.safe_distance:\n                    return True\n\n        return False\n\n    def generate_avoidance_command(self, obs_x, obs_y):\n        """Generate command to avoid obstacles"""\n        cmd_vel = Twist()\n\n        # Calculate obstacle centroid\n        if len(obs_x) > 0:\n            centroid_x = np.mean(obs_x)\n            centroid_y = np.mean(obs_y)\n\n            # Determine avoidance direction\n            if centroid_y > 0:  # Obstacle on the right\n                cmd_vel.angular.z = self.max_angular_speed * 0.7\n            else:  # Obstacle on the left\n                cmd_vel.angular.z = -self.max_angular_speed * 0.7\n\n            # Reduce linear speed during avoidance\n            cmd_vel.linear.x = self.max_linear_speed * 0.3\n\n        return cmd_vel\n\n    def follow_path_command(self):\n        """Generate command to follow the planned path"""\n        cmd_vel = Twist()\n\n        if (self.current_path is None or\n            self.robot_pose is None or\n            len(self.current_path.poses) == 0):\n            return cmd_vel\n\n        # Get current robot position\n        robot_x = self.robot_pose.position.x\n        robot_y = self.robot_pose.position.y\n\n        # Find the closest waypoint\n        min_dist = float(\'inf\')\n        closest_idx = self.path_index\n\n        for i in range(self.path_index, len(self.current_path.poses)):\n            pose = self.current_path.poses[i].pose.position\n            dist = math.sqrt((pose.x - robot_x)**2 + (pose.y - robot_y)**2)\n\n            if dist < min_dist:\n                min_dist = dist\n                closest_idx = i\n\n        # Update path index to closest point\n        self.path_index = closest_idx\n\n        # Get target waypoint (a few steps ahead for smoother navigation)\n        target_idx = min(self.path_index + 3, len(self.current_path.poses) - 1)\n        target_pose = self.current_path.poses[target_idx].pose.position\n\n        # Calculate direction to target\n        dx = target_pose.x - robot_x\n        dy = target_pose.y - robot_y\n        target_angle = math.atan2(dy, dx)\n\n        # Calculate distance to target\n        dist_to_target = math.sqrt(dx**2 + dy**2)\n\n        # Simple proportional controller\n        cmd_vel.linear.x = max(self.min_linear_speed,\n                              min(self.max_linear_speed, dist_to_target * 0.5))\n        cmd_vel.angular.z = target_angle * 1.5  # Proportional gain\n\n        # Limit angular velocity\n        cmd_vel.angular.z = max(-self.max_angular_speed,\n                               min(self.max_angular_speed, cmd_vel.angular.z))\n\n        # Check if we\'ve reached the goal\n        goal_pose = self.current_path.poses[-1].pose.position\n        goal_dist = math.sqrt((goal_pose.x - robot_x)**2 + (goal_pose.y - robot_y)**2)\n\n        if goal_dist < 0.3:  # Close enough to goal\n            cmd_vel.linear.x = 0.0\n            cmd_vel.angular.z = 0.0\n            self.navigation_active = False\n\n            # Publish completion status\n            status_msg = Bool()\n            status_msg.data = False\n            self.status_pub.publish(status_msg)\n\n            self.get_logger().info(\'Navigation goal reached!\')\n\n        return cmd_vel\n\n    def publish_navigation_markers(self):\n        """Publish visualization markers for navigation"""\n        marker_array = MarkerArray()\n\n        # Implementation would create markers for path, obstacles, etc.\n\n        self.marker_pub.publish(marker_array)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = CompleteNavigationSystem()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        print("Shutting down navigation system...")\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,s.jsx)(e.h3,{id:"step-3-test-the-navigation-system",children:"Step 3: Test the Navigation System"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:"Run the complete navigation system:"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"python3 complete_navigation_system.py\n"})}),"\n",(0,s.jsxs)(e.ol,{start:"2",children:["\n",(0,s.jsx)(e.li,{children:"Send navigation goals using RViz or command line:"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"# Send a goal using command line\nros2 action send_goal /navigate_to_pose geometry_msgs/PoseStamped \"{header: {frame_id: 'map'}, pose: {position: {x: 5.0, y: 5.0, z: 0.0}, orientation: {w: 1.0}}}\"\n"})}),"\n",(0,s.jsx)(e.h2,{id:"tuning-and-optimization",children:"Tuning and Optimization"}),"\n",(0,s.jsx)(e.h3,{id:"navigation-parameter-tuning",children:"Navigation Parameter Tuning"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.node import Node\nfrom rcl_interfaces.msg import ParameterDescriptor\nfrom rclpy.parameter import Parameter\nfrom std_msgs.msg import String\n\nclass NavigationTuner(Node):\n    def __init__(self):\n        super().__init__('navigation_tuner')\n\n        # Declare parameters with descriptions\n        self.declare_parameter('linear_vel_max', 0.5,\n                              ParameterDescriptor(description='Maximum linear velocity'))\n        self.declare_parameter('angular_vel_max', 1.0,\n                              ParameterDescriptor(description='Maximum angular velocity'))\n        self.declare_parameter('safe_distance', 0.5,\n                              ParameterDescriptor(description='Minimum safe distance to obstacles'))\n        self.declare_parameter('inflation_radius', 0.55,\n                              ParameterDescriptor(description='Costmap inflation radius'))\n\n        # Publisher for tuning updates\n        self.tuning_pub = self.create_publisher(String, '/tuning_updates', 10)\n\n        # Timer for parameter monitoring\n        self.timer = self.create_timer(1.0, self.check_parameters)\n\n        self.get_logger().info('Navigation Tuner initialized')\n\n    def check_parameters(self):\n        \"\"\"Monitor and report parameter values\"\"\"\n        linear_vel = self.get_parameter('linear_vel_max').value\n        angular_vel = self.get_parameter('angular_vel_max').value\n        safe_dist = self.get_parameter('safe_distance').value\n        inflation = self.get_parameter('inflation_radius').value\n\n        # Log current values\n        self.get_logger().info(\n            f'Current parameters - Linear: {linear_vel}, '\n            f'Angular: {angular_vel}, Safe dist: {safe_dist}, '\n            f'Inflation: {inflation}'\n        )\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = NavigationTuner()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,s.jsx)(e.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Safety First"}),": Always maintain safe distances from obstacles"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Stability"}),": Use appropriate speeds for humanoid robot stability"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Sensor Fusion"}),": Combine multiple sensor sources for robust navigation"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Path Smoothing"}),": Smooth paths to reduce jerky movements"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Recovery Behaviors"}),": Implement robust recovery behaviors for stuck situations"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Parameter Tuning"}),": Continuously tune parameters based on performance"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsx)(e.p,{children:"After completing this chapter, you'll be ready to learn about path planning specifically for bipedal humanoid movement in Chapter 5."})]})}function p(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(c,{...n})}):c(n)}},8453:(n,e,a)=>{a.d(e,{R:()=>r,x:()=>i});var t=a(6540);const s={},o=t.createContext(s);function r(n){const e=t.useContext(o);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function i(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:r(n.components),t.createElement(o.Provider,{value:e},n.children)}}}]);